S/N,Subject Description,Topic ,Text1.      ,OPERATING SYSTEM,Meaning of Operating systems,"An operating system (commonly abbreviated OS or O/S) is the software component of a computer system that is responsible for the management and coordination of activities and the sharing of the resources of the computer. The operating system acts as a host for applications that are run on the machine. As a host, one of the purposes of an operating system is to handle the details of the operation of the hardware. This relieves application programs from having to manage these details and this makes it easier to write applications. Almost all computers, including handheld computers, desktop computers, supercomputers, and even video game consoles, use an operating system of some type. Some of the oldest models may however use an embedded operating system that may be contained on a compact disk or other data storage device.",,,"Operating systems offer a number of services to application programs and users. Applications access these services through application programming interfaces (APIs) or system calls. By invoking these interfaces, the application can request a service from the operating system, pass parameters, and receive the results of the operation. Users may also interact with the operating system with some kind of software user interface (UI) like typing commands using command line interface (CLI) or using a graphical user interface (GUI, commonly pronounced “gooey”). For hand-held and desktop computers, the user interface is generally considered part of the operating system. On large multi-user systems like Unix and Unix-like systems, the user interface is generally implemented as an application program that runs outside the operating system. (Whether the user interface should be included as part of the operating system is a point of contention).",,,"Common contemporary operating systems include Microsoft Windows, Mac OS, Linux and Solaris. Microsoft Windows has a significant majority of the market share in the desktop and notebook computer markets, while servers generally run on Linux or other Unix-like systems. Embedded device markets are split amongst several operating systems."2.      ,,Modern computer,"Modern Computer consists of one or more processors, some main memory, disks, printers, a keyboard, a mouse, a display, network interfaces, and various other input/output devices."3.      ,,Deadlock,"Deadlock is a paralyzing process state resulting from improper CPU scheduling, process management, and synchronization management. During this time, processes are blocked as they compete for system resources or only communicate with each other. Although it cannot be guaranteed that deadlock may be avoided 100% of the time, it is important to know how to avoid the deadlocked state and how to recover from it once it has been achieved. We will build upon the previous two units of CPU Scheduling and Processes and Threads when discussing Deadlock. First, we will discuss what deadlock is by establishing a working definition and the conditions in which it presents itself. Then, we will talk about how to prevent and avoid deadlock. Finally, we will learn about deadlock detection, as well as methods for recovering from a deadlocked state.",,,4.      ,,Types of Operating Systems,"Operating systems are classified based on the number of users into single user, multi-user and network operating systems. ",,,"a.     Single-user operating systems: Single-user operating systems are designed to run on stand-alone microcomputers or PCs. Their primary function is to manage the resources of that PC and control its activities in its entirety. Examples are: MS-DOS, PC -DOS, CP/M, Windows 3.1 etc. ",,,"b.     Multi-User Operating System: The multi-user operating systems were prevalent during the era of centralized processing of jobs on a host (CPU) to which other terminals (Dummy terminals) are connected. These operating systems run on minicomputer systems. Examples are: PC-MOS, and UNIX. ",,,c.     Network Operating System: Network operating systems are primarily concerned with communication among the various systems and peripherals on the network; as well as the flow of data across the network and sharing of resources on the network.5.      ,,System calls,"System calls provide an interface between a running program (process) and the operating system. System calls allow user-level processes to request some services from the operating system which the process itself is not allowed to do. In handling the trap, the operating system will enter in the kernel mode, where it has access to privileged instructions, and can perform the desired service on behalf of user-level process. It is because of the critical nature of operations that the operating system itself does them every time they are needed. For example, for I/O, a process involves a system call telling the operating system to read from, or to write to a particular area and this request is satisfied by the operating system.",,,"A system call is a request made by any program to the kernel for performing tasks, picked from a predefined set, which the said program does not have the required permissions to execute in its own flow of execution. System calls provide the interface between a process and the kernel. These calls are generally available as assembly language instructions and they are usually listed in the various manuals used by the assembly-language programmers. Most operations interacting with the system require permissions not available to a user level process, i.e. any I/O operation performed with any arbitrary device present on the system or any form of communication with other processes requires the use of system calls."6.      ,,Types of system calls and their purposes,"·       Process control: This type of system calls are used to control processes. Some examples are: end, abort, load, execute, create process, terminate process; get process attributes, set process attributes, wait for time, wait event, signal event, allocate and free memory. ",,,"·       File management: This type of system calls are used to manage files. Some examples are: create file(s), delete file(s), open, close, read, write, reposition, get file attributes, set file attributes. ",,,"·       Device management: This type of system calls are used to manage devices. Some examples are: request device, release device, read, write, reposition, get device attributes, set device attributes, logically attach or detach devices. ",,,"·       Information maintenance: This type of system calls are used to get information from the computer. Some examples are: get time or date, set time or date; get system data, set system data; get process, file, or device attributes; set process, file, or device attributes. ",,,"·       Communication: This type of systems calls are used for communication. Some examples are: create, delete communication connection; send, receive messages; and transfer status information."7.      ,,Process Scheduling,"Once the job scheduler has moved a job from new to ready state, it creates one or more processes for this job. The process scheduling module decides which processes in the ready state get the processor, when, and for how long? Specifically, the process scheduler performs the following tasks:",,,"1.     Keeping track of the status of the process (all processes are either running, ready, or blocked). The module that performs this function has been called the traffic controller. ",,,2.     Deciding which process gets a processor and for how long. This is performed by the processor scheduler. ,,,3.     Allocating a processor to a process. This requires resetting of processor registers to correspond to the process’ correct state. This task is performed by the traffic controller. ,,,"4.     Deallocating a processor, such as when the running process exceeds its current quantum or must wait for an I/O completion. This requires that all processor state registers be saved to allow future reallocation. This task is performed by the traffic controller."8.      ,,Process creation,"When a new process is to be added to those currently being managed, the OS builds the data structures that are used to manage the process and allocates address in main memory to the process. These actions constitute the creation of a new process. In process creation, parents process create children processes, which in turn can create other processes forming a tree of processes. Resources are shared among parents and children and parents and children execute jobs concurrently."9.      ,,Process Termination,"A process terminates when it finishes executing its final statement and asks the operating system to delete it by using the exit() system call. At that point, the process may return a status value (typically an integer) to its parent process (via the wait() system call). All the resources of the process—including physical and virtual memory, open files, and I/O buffers—are deallocated by the operating system. ",,,"A parent may terminate the execution of one of its children for a variety of reasons, such as these: ",,,"• The child has exceeded its usage of some of the resources that it has been allocated. (To determine whether this has occurred, the parent must have a mechanism to inspect the state of its children.). ",,,• The task assigned to the child is no longer required. ,,,"• The parent is exiting, and the operating system does not allow a child to continue if its parent terminates."10.   ,,Definition of operating System,"An Operating System is intimately tied to the Hardware of the Computer it runs on. It extends the computer’s instruction set and manages its resources. To work, it must know a great deal about the Hardware, at least about how the hardware appears to the Programmer. Operating Systems differ from user (i.e., application) programs in ways other than where they reside. In particular, they are huge, complex, and long-lived. The source code of the heart of an operating system like Linux or Windows is on the order of five million lines of code or more."11.   ,,Definition of CPU,"The ‘‘Brain’’ of the computer is the CPU. It fetches instructions from memory and executes them. The basic cycle of every CPU is to fetch the first instruction from memory, decode it to determine its type and operands, execute it, and then fetch, decode, and execute subsequent instructions. The cycle is repeated until the program finishes."12.   ,,Process ,This is a general term for a program which is being executed. All work done by the CPU contributes to the execution of processes. Each process has a descriptive information structure associated with it (normally held by the kernel) called a process control block which keeps track of how far the execution has progressed and what resources the process holds.,,,"Processes can exchange messages by using four system calls: msgget (), msgsnd (), msgrcv (), and msgctl (). The msgget () function converts a mailbox name to a message queue id, msqid, the internal identifier returned by msgget (), must be passed to all subsequent system calls using this message queue to facilitate interprocess communication."13.   ,,Thread ,"A Thread (sometimes called a lightweight process) is different from process or task in that a thread is not enough to get a whole program executed. A thread is a kind of stripped down process, it is just one ‘active hand’ in a program, something which the CPU is doing on behalf of a program, but not enough to be called a complete process.",,,"A Thread is a basic unit of CPU utilization; it comprises a Thread ID, a Program counter, a Register set, and a Stack. It shares with other threads belonging to the same process its code section, data section, and other Operating system resources, such as open files and signals. A traditional (or heavyweight :) process has a single thread of control. If a Process has multiple threads of control, it can perform more than one task at a time."14.   ,,ENIAC ,"The First General-Purpose Electronic Computer, the ENIAC, had 18000 Vacuum tubes and consumed 140000 watts of power. As a result, it ran up a nontrivial electricity bill. After the invention of the Transistor, Power usage dropped dramatically and the computer industry lost interest in power requirements. However, nowadays power management is back in the spotlight for several reasons, and the operating system is playing a role here."15.   ,,Battery ,"Batteries come in two general types: Disposable and Rechargeable. Disposable batteries (most commonly AAA, AA, and D cells) can be used to run handheld devices, but do not have enough energy to power notebook computers with large bright screens. A Rechargeable battery, in contrast, can store enough energy to power a notebook for a few hours. Nickel-cadmium batteries used to dominate here, but they gave way to Nickel Metal Hydride Batteries, which last longer and do not pollute the environment quite as badly when they are eventually discarded."16.   ,,Scheduling,"The aim of processor scheduling is to assign processes to be executed by the processor or processes over time in a way that meets system objectives such as response time, throughput and processor efficiency. ",,,There are four types of scheduling: ,,,·       Long-term scheduling: This involves the decision to add to the pool of processes to be executed. It is also known as high-level scheduling. ,,,·       Medium-term scheduling: This involves the decision to add to the number of processes that are partially or fully in main memory.,,,·       Short-term scheduling: This involves the decision as to which available process will be executed by the processor. It is also known as low-level scheduling or the dispatcher.,,,·       I/O scheduling: This involves the decision as to which process’s pending I/O requests shall be handled by the available I/O device.,,,17.   ,,Mutual Exclusions with Semaphores,A semaphore is a non-negative integer value. Two atomic operations are supported on a semaphore: ,,,"• down = decrement the value, since the value cannot be negative, the process blocks if the value is zero. ",,,"• up = increment the value, if there are any processes waiting to perform a down, then they are unblocked.  ",,,v  Initializing a semaphore to 1 creates a mutual exclusion (mutex) semaphore. ,,,v  Initializing a semaphore to 0 creates a signaling semaphore. ,,,v  Initializing a semaphore to other values can be used for resource allocation and synchronization.,,,18.   , ,What are Monitors?,"Monitors provide a structured concurrent programming primitive, which is used by processes to ensure exclusive access to resources, and for synchronizing and communicating among users. A monitor module encapsulates both a resource definition and operations/procedures that exclusively manipulate it. Those procedures are the gateway to the shared resource and called by the processes to access the resource. Only one call to a monitor procedure can be active at a time and this protects data inside the monitor from simultaneous access by multiple users. Thus mutual exclusion is enforced among tasks using a monitor. Processes that attempt monitor entry while the monitor is occupied are blocked on a monitor entry queue. ",,,"To synchronize tasks within the monitor, a condition variable is used to delay processes executing in a monitor. It may be declared only within a monitor and has no numeric value like semaphores do. Two operations, wait and signal, are defined on condition variables. The wait operation suspends/blocks execution of the calling process if a certain condition is true, then the monitor is unlocked and allows another task to use the monitor. When the same condition becomes false, then the signal operation resumes execution of some processes suspended after a wait on that condition, by placing it in the processor ready queue. If there are several such processes, choose one of them; if there are no waiting processes, the signal operator is ignored. Therefore, the introduction of condition variables allows more than one process to be in the same monitor at the same time, although only one of them will be actually active within that monitor.",,,"A condition variable is associated with a queue of the processes that are currently waiting on that condition. First-in-first-out (FIFO) discipline is generally used with queues, but priority queues can also be implemented by specifying the priority of the process to be delayed as a parameter in the wait operation. (Condition variables are assumed to be fair in the sense that a process will not remain suspended forever on a condition variable that is signaled infinitely often.) Therefore, monitors allow flexibility in scheduling of the processes waiting in queues."19.   ,,Messaging passing,Messaging passing system allow processes to communicate with one another without the need to resort to shared data. An IPC facility provides at least the two operations send (message) and receive (message). Communication between processes takes place by calls to send() and receive() primitives. There are different design options for implementing each primitive. Message passing may be either blocking or non-blocking—also known as synchronous and asynchronous. .Processes communicates with each other directly or indirectly without resorting to shared variables. Processes must name each other explicitly.20.   ,,Deadlock,"Deadlock can be defined as the permanent blocking of a set of processes that either compete for system resources or communicate with each other. A set of processes is deadlock when each process in the set is blocked awaiting an event (typically the freeing up of some requested resources) that can only be triggered by another blocked process in the set. Deadlock is permanent when none of the events is ever triggered. Unlike other problems in concurrent process management, there is no efficient solution in the general case. A common example is the traffic deadlock."21.   ,,Deadlock Prevention,"The strategy of deadlock prevention is, simply to design a system in such a way that the possibility of deadlock is excluded. We can view deadlock prevention methods as falling into two classes. An indirect method of deadlock prevention is to prevent the occurrence of one of the three necessary conditions listed previously (items 1 through 3). A direct method of deadlock prevention is to prevent the occurrence of a circular wait (item 4). We now examine techniques related to each of the four conditions. ",,,"v  Mutual Exclusion: In general, the first of the four listed conditions cannot be disallowed. If access to a resource requires mutual exclusion, then mutual exclusion must be supported by the operating system. Some resources, such as files, may allow multiple accesses for reads but only exclusive access for writes. Even in this case, deadlock can occur if more than one process requires write permission.",,,"v  Hold and Wait: The hold-and-wait condition can be prevented by requiring that a process request all of its required resources at one time and blocking the process until all requests can be granted simultaneously. This approach is inefficient in two ways. First, a process may be held up for a long time waiting for all of its resource requests to be fulfilled, when in fact it could have proceeded with only some of the resources. Second, resources allocated to a process may remain unused for a considerable period during which time they are denied to other processes. Another problem is that a process may not know in advance all of the resources that it will require. There is also the practical problem created by the use of modular programming or a multithreaded structure for an application. An application would need to be aware of all resources that will be required at all levels or in all modules to make the simultaneous request. ",,,"v  No preemption: This condition can be prevented in several ways. First, if a process holding certain resources is denied a further request, that process must release its original resources and, if necessary, request them again together with the additional resource. Alternatively, if a process requests a resource that is currently held by another process, the operating system may preempt the second process and require it to release its resources. This latter scheme would prevent deadlock only if no two processes possessed the same priority. This approach is practical only when applied to resources whose state can be easily saved and restored later, as is the case with a processor. ",,,"v  Circular wait: The circular wait condition can be prevented by defining a linear ordering of resource types. If a process has been allocated resources of type R, then it may subsequently request only resources of types following R in the ordering."22.   ,,Deadlock Avoidance,"An approach to solving the deadlock problem that differs subtly from deadlock prevention is deadlock avoidance. In deadlock prevention, we constrain resource requests to prevent at least one of the four conditions of deadlock. This is either done indirectly, by preventing one of the three necessary policy conditions (mutual exclusion, hold and wait, no preemption), or directly, by preventing circular wait. This leads to inefficient use of resources and inefficient execution of processes. Deadlock avoidance, on the other hand, allows the three necessary conditions but makes judicious choices to assure that the deadlock point is never reached. As such, avoidance allows a more concurrency than prevention. With deadlock avoidance, a decision is made dynamically whether the current resource allocation request will, if granted, potentially lead to a deadlock. Deadlock avoidance thus requires knowledge of future process resource requests."23.   ,,Bugs,"Bugs refer to errors in a program, and the process of removing them (error correction) is called debugging. Debuggers allow us to step through the codes in a program, stepping over or into functions and methods with a view to correcting the errors (bugs) in the program. When we debug in a top-down fashion we initially step over bodies of code we consider irrelevant, narrowing down our search as we come nearer the problem’s manifestation. This strategy requires patience and persistence. Often we step-over a crucial function and find ourselves having to repeat the search aiming to step-into the function the next time round."24.   ,,Memory Management Concepts,"The main purpose of a computer is to execute programs to produce result (information). These programs, together with the data they access, must be in main memory (at least partially during execution). In a uniprogramming system, main memory is divided into two parts: one part for the operating system and another for the program currently being executed. In a multiprogramming system, the “user” part of memory must be further subdivided to accommodate multiple processes. The task of subdivision is carried out dynamically by the operating system and is known as memory management. To improve both the utilization of the CPU and the speed of its response to users, the computer must keep several processes in memory."25.   ,,Single Contiguous Memory Allocation,"Single contiguous allocation is a simple memory management scheme that requires no special hardware features. It is usually associated with small stand-alone computers (or minicomputers) with simple batch operating system, e.g. IBM OS/360 Primary Control Program, IBM 1130 Disk Monitor System, IBM 7094 Fortran Monitor System. In such a systems, there is no multiprogramming, and one to one correspondence exists between a user, and a job, or a process. Thus the terms job, or process may be used interchangeably. ",,, The term job or process is defined as a program in execution or an instance of a program running on a computer. A user is a person that submits a job or request to the computer for execution.,,," Memory is conceptually divided into three contiguous regions. A portion of memory is permanently allocated to the operating system. All of the remainder of memory is available (and allocated) to the single job being processed. The job actually uses a portion of the allocated memory, leaving an allocated but unused region of memory. For example, if there are 256K bytes of memory, a simple operating system may require 32k bytes, leaving 224k bytes allocated for user jobs. If a typical job requires only 64k bytes, then 160k bytes of memory (over 50 % of the memory) unused."26.   ,,Translation lookaside buffer (TLB),"A Translation lookaside buffer (TLB) is a CPU cache that memory management hardware uses to improve virtual address translation speed. It was the first cache introduced in processors. All current desktop and server processors (such as x86) use a TLB. A TLB has a fixed number of slots that contain page table entries, which map virtual addresses to physical addresses. It is typically a content-addressable memory (CAM), in which the search key is the virtual address and the search result is a physical address. If the requested address is present in the TLB, the CAM search yields a match quickly, after which the physical address can be used to access memory. This is called a TLB hit. If the requested address is not in the TLB, the translation proceeds by looking up the page table in a process called a page walk. The page walk is a high latency process, as it involves reading the contents of multiple memory locations and using them to compute the physical address. Furthermore, the page walk takes significantly longer if the translation tables are swapped out into secondary storage, which a few systems allow. After the physical address is determined, the virtual address to physical address mapping and the protection bits are entered in the TLB."27.   ,,Memory Partition Selection Algorithm,v  First -fit An incoming process is placed in the first available hole which can accommodate it. ,,,"v  Best-fit An incoming process is placed in a hole in which it fits mostly tightly, i.e. for all the choices of hole, the difference between the hole size and the new process size is least. ",,,"v  Worst-fit An incoming process is placed in the hole which leaves the maximum amount of unused space, which logically must be the current largest hole."28.   ,,Virtual memory concepts,Virtual Memory refers to the concept whereby a process with a larger size than available memory can be loaded and executed by loading the process in parts. The program memory is divided into pages and the available physical memory into frames. The page size is always equal to the frame size. The page size is generally in a power of 2 to avoid the calculation involved to get the page number and the offset from the CPU generated address. The virtual address contains a page number and an offset. This is mapped to the physical address by a technique of address resolution after searching the Page Map Table.29.   ,,Demand Paging,"In Virtual Memory Systems the pages are not loaded in memory until they are ""demanded"" by a process; therefore the term, demand paging. Demand paging allows the various parts of a process to be brought into physical memory as the process needs them to execute. This normally involves a memory management unit which looks up the virtual address in a page map to see if it is paged in. If it is not then the operating system will page it in, update the page map and restart the failed access. This implies that the processor must be able to recover from and restart a failed memory access or must be suspended while some other mechanism is used to perform the paging. ",,,"Paging in a page may first require some other page to be moved from main memory to disk (""paged out"") to make room. If this page has not been modified since it was paged in, it can simply be reused without writing it back to disk. This is determined from the ""modified"" or ""dirty"" flag bit in the page map. A replacement algorithm or policy is used to select the page to be paged out; often this is the least recently used (LRU) algorithm. ",,,"In computer operating systems, demand paging is an application of virtual memory. In a system that uses demand paging, the operating system copies a disk page into physical memory only if an attempt is made to access it (i.e., if a page fault occurs). It follows that a process begins execution with none of its pages in physical memory, and many page faults will occur until most of a process's working set of pages is located in physical memory. This is an example of a lazy loading techniques."30.   ,,Prepaging,"A technique whereby the operating system in a paging virtual memory multitasking environment loads all pages of a process's working set into memory before the process is restarted. Under demand paging a process accesses its working set by page faults every time it is restarted. Under prepaging, the system remembers the pages in each process's working set and loads them into physical memory before restarting the process. Prepaging reduces the page fault rate of reloaded processes and hence generally improves CPU efficiency. Prepaging is generally more efficient than demand paging.",,,31.   ,,Thrashing,"Thrashing is a degenerate case that occurs when there is insufficient memory at one level in the memory hierarchy to properly contain the working set required by the upper levels of the memory hierarchy. This can result in the overall performance of the system dropping to the speed of a lower level in the memory hierarchy. Therefore, thrashing can quickly reduce the performance of the system to the speed of main memory or, worse yet, the speed of the disk drive. ",,,"There are two primary causes of thrashing: (1) insufficient memory at a given level in the memory hierarchy, and (2) the program does not exhibit locality of reference. If there is insufficient memory to hold a working set of pages or cache lines, then the memory system is constantly replacing one block (cache line or page) with another. As a result, the system winds up operating at the speed of the slower memory in the hierarchy. A common example occurs with virtual memory. A user may have several applications running at the same time and the sum total of these programs' working sets is greater than all of physical memory available to the program. As a result, as the operating system switches between the applications it has to copy each application's data to and from disk and it may also have to copy the code from disk to memory. Since a context switch between programs is often much faster than retrieving data from the disk, this slows the programs down by a tremendous factor since thrashing slows the context switch down to the speed of swapping the applications to and from disk.",,,"If the program does not exhibit locality of reference and the lower memory subsystems are not fully associative, then thrashing can occur even if there is free memory at the current level in the memory hierarchy. For example, suppose an eight kilobyte L1 caching system uses a direct mapped cache with 16-byte cache lines (i.e., 512 cache lines). If a program references data objects 8K apart on each access then the system will have to replace the same line in the cache over and over again with each access. This occurs even though the other 511 cache lines are currently unused."32.   ,,Page replacement algorithm for multiple process,"Up to this point, we have been assuming that there is only one active process. When there are multiple processes, things get more complicated. Algorithms that work well for one process can give terrible results if they are extended to multiple processes in a naive way. ",,,"LRU would give excellent results for a single process, and all of the good practical algorithms can be seen as ways of approximating LRU. A straightforward extension of LRU to multiple processes still chooses the page frame that has not been referenced for the longest time. However, that is a lousy idea. Consider a workload consisting of two processes. Process A is copying data from one file to another, while process B is doing a CPU-intensive calculation on a large matrix. Whenever process A blocks for I/O, it stops referencing its pages. After a while process B steals all the page frames away from A. When A finally finishes with an I/O operation, it suffers a series of page faults until it gets back the pages it needs, then computes for a very short time and blocks again on another I/O operation. ",,,"Various specific algorithms have been proposed. As in the single process case, some are theoretically good but unimplementable, while others are easy to implement but bad. The trick is to find a reasonable compromise."33.   ,,I/O Operations,"There are three techniques used for I/O operations: a. Programmed I/O b. Interrupt-Driven I/O, and c. Direct Memory Access (DMA)",,,"v  Programmed I/O: With programmed I/O, data are exchanged between the CPU and I/O module. The CPU executes a program that gives it direct control of the I/O operations including sending a read or write command and transferring the data. When the CPU issues a command to the I/O module, it must wait until the I/O operation is complete. If the CPU is faster than the I/O module, the CPU time is wasted. The I/O module takes no further action to alert the CPU. In particular, it does not interrupt the CPU. Thus it is the responsibility of the CPU to periodically check the status of the I/O module until it finds that the operation is complete.",,,"v  Interrupt – Driven I/O: With Interrupt-driven I/O, the CPU issues an I/O command, continues to execute other instructions, and is interrupted by the I/O module when the latter has completed its work. The problem with program I/O is that the CPU has to wait a long time for the I/O module to be ready for either reception or transmission of data. The CPU, while waiting, must repeatedly interrogate the status of the I/O module. As a result, the level of performance of the entire system is severely degraded. An alternative is for the CPU to issue an I/O command to a module and then request service when it is ready to exchange data with the CPU. The CPU then executes the data transfer, as before, and resumes its former processing.",,,"v  Direct Memory Access (DMA): With this technique, the I/O module and the main memory exchange data directly without CPU involvement. DMA involves an additional module on the system bus. The DMA module is capable of mimicking the CPU and indeed capable of taking over control of the system from the CPU. The technique works as follows: when the CPU wishes to read or write a block of data, it issues a command to the DMA module, by sending to the DMA module the following information: ",,,·       Whether a read or write is requested. ,,,·       The address of the I/O device involved. ,,,·       The starting location in memory to read from or write to. ,,,·       The number of words to be read or written.34.   ,,File Concepts,"For most users, the file system is the most visible aspect of an operating system. It provides the mechanism for on-line storage of and access to both data and programs of the operating system and all the users of the computer system. The file system consists of two distinct parts: a collection of files, each storing related data, and a directory structure, which organizes and provides information about all the files in the system. Computers can store information on several different storage media, such as magnetic disks, magnetic tapes, and optical disks. So that the computer system will be convenient to use, the operating system provides a uniform logical view of information storage. The operating system abstracts from the physical properties of its storage devices to define a logical storage unit (the file). Files are mapped, by the operating system, onto physical devices. These storage devices are usually nonvolatile, so the contents are persistent through power failures and system reboots. A file is a named collection of related information that is recorded on secondary storage. From a user’s perspective, a file is the smallest allotment of logical secondary storage; that is, data cannot be written to secondary storage unless they are within a file. Commonly, files represent programs (both source and object forms) and data. Data files may be numeric, alphabetic, or alphanumeric etc. Files may be free form, such as text files, or may be formatted rigidly. In general, a file is a sequence of bits, bytes, lines, or records, the meaning of which is defined by the file’s creator and user. The concept of a file is thus extremely general. The information in a file is defined by its creator. Many different types of information may be stored in a file – source programs, object programs, executable programs, numeric data, text, payroll records, graphic images, sound recordings, and so on."35.   ,,File Attributes,"A file is named, for the convenience of its human users, and is referred to by its name. A name is usually a string of characters, such as example.c. Some systems differentiate between upper and lowercase characters in names, whereas other systems consider the two cases to be equivalent. When a file is named, it becomes independent of the process, the user, and even the system that created it. For instance, one user might create the file example.c, whereas another user might edit that file by specifying its name. The file’s owner might write the file to a floppy disk, send it in an e-mail, or copy it across a network, and it could still be called example.c on the destination system. A file has certain other attributes, which vary from one operating system to another, but typically consists of these: Name, Identifier, Type, Location, Size, Protection, Time, date and user identification. ",,,The information about all files is kept in the directory structure that also resides on secondary storage.36.   ,,File Operations,"A file is an abstract data type. To define a file properly, we need to consider the operations that can be performed on files. The operating system can provide system calls to create, write, read, reposition, delete, and truncate files. The following are five basic operations of the operating systems on files:",,,Ø  Creating a file ,,,Ø  Writing a file,,,Ø  Reading a file,,,Ø  Deleting a file ,,,Ø  Truncating a file ,,,These five basic operations certainly comprise the minimal set of required file operations. Other common operations include appending new information to the end of an existing file and renaming the file.37.   ,,ACCESS METHODS,"Files store information, when it is used, this information must be accessed and read into computer memory. The information in the file can be accessed in several ways. Some systems provide only one access method for files. Other systems, support many access methods.",,,"Ø  Sequential File: In sequential file, records are stored one after the other in a predetermined form. This order is determined by the key fields on each record such as student matriculation number. An example is a magnetic tape where records/files are stored sequentially. To locate a particular record/file implies searching from the beginning of the sequentially file, one after the other until the record is located.",,,"Ø  Direct File: Records in a direct file are not stored physically one after the other, rather, they are stored on a disk with a particular address or location that can be determined by their key field. The file allows programs to read and write records rapidly in no particular order. The direct access is based on disk model since disk allows random access to any file block.",,,Ø  Index Sequential file: This is a compromise between sequential and direct file. It stores records in a file in a sequential order but has an index associated with it. The index lists the key to each group of records stored and the corresponding disk address for that group. This is similar to the index at the end of a book that gives easy access to the content.38.   ,,Hardware protection,"A properly designed OS must ensure that an incorrect (or malicious) program cannot cause other programs to execute incorrectly. Many programming errors are detected by the hardware. These errors are normally handled by the operating system. If a user program fails in some way, such as by making an attempt either to execute an illegal instruction, or to access memory that is not in the user’s address space, then the hardware will trap to the operating system, just like an interrupt. Whenever a program error occurs, the operating system must normally terminate the program. The following will be discussed: I/O Protection, Memory Protection and CPU Protection.",,,"Ø  I/O Protection: A user program may disrupt the normal operation of the system by issuing illegal I/O instructions, by accessing memory locations within the operating system itself, or by refusing to relinquish the CPU. We can use various mechanisms to ensure that such disruptions cannot take place in the system. To prevent users from performing illegal I/O, we define all I/O instructions to privileged instructions. Thus, users cannot issue I/O instructions directly, they must do it through the operating system.",,,"Ø  Memory Protection: To ensure correct operation, we must protect the interrupt vector from Modification by a user program. In addition, we must also protect the interrupt-service routines in the operating system from modification. Even if the user did not gain unauthorized control of the computer, modifying the interrupt service routines would probably disrupt the proper operation of the computer system. We see that we must provide memory protection at least for the interrupt vector and the interrupt-service routines of the operating system. In general, we want to protect the operating system from access by user programs, and in addition, to protect user programs from one another. This protection must be provided by the hardware.",,,"Ø  CPU Protection: In addition to protecting I/O and memory, we must ensure that the operating system maintains control. We must prevent a user program from getting stuck in an infinite loop or not calling system services, and never returning control to the operating system. To accomplish this goal, we can use a timer. A timer can be set to interrupt the computer after a specified period. The period may be fixed or variable. Before turning over control to the user, the OS ensures that the timer is set to interrupt. If the timer interrupts, control transfers automatically to the OS, which may treat the interrupt as a fatal error or may give the program more time. Clearly, instructions that modify the operation of the timer are privileged."39.   ,,Context Switch,"When CPU switches to another process, the system must save the state of the old process and load the saved state for the new process. Context-switch time is additional overhead, the system does no useful work while switching. Switching can be time dependent on hardware support. The operating system is responsible for the following activities in connection with process management:",,,Ø  Creating and deleting both user and system processes ,,,Ø  Suspending and resuming processes ,,,Ø  Providing mechanisms for process synchronization ,,,Ø  Providing mechanisms for process communication ,,,Ø  Providing mechanisms for deadlock handling40.   ,,Cooperating processes,"The concurrent processes executing in the operating system may be either independent processes or cooperating processes. A process is independent if it cannot affect or be affected by the other processes executing in the system. Any process that does not share data (temporary or persistent) with any other process is independent. A process is cooperating if it can affect or be affected by the other processes executing in the system. Clearly, any process that shares data with other processes is a cooperating process. ",,,There are several reasons for providing an environment that allows process cooperation: ,,,"·       Information sharing: Since several users may be interested in the same piece of information (for instance, a shared file), we must provide an environment to allow concurrent access to these types of resources. ",,,"·       Computation speedup: If we want a particular task to run faster, we must break it into subtasks, each of which will be executing in parallel with the others. Notice that such a speedup can be achieved only if the computer has multiple processing elements (such as CPUs or I/O channels). ",,,"·        Modularity: We may want to construct the system in a modular fashion, dividing the system functions into separate processes or threads, as shall be discussed later in the lecture. ",,,"·       Convenience: Even an individual user may work on many tasks at the same time. For instance, a user may be editing, printing, and compiling in parallel. Concurrent execution that requires cooperation among the processes requires mechanisms to allow processes to communicate with one another and to synchronize their actions."41.   ,COMPUTER NETWORKING,Local Area Network,"Local Area Networks, or LANs, are the “physical” networks that provide the connection between machines within, say, a home, school or corporation. LANs are, as the name says, “local”; it is the IP, or Internet Protocol, layer that provides an abstraction for connecting multiple LANs into, well, the Internet. Finally, TCP deals with transport and connections and actually sending user data."42.   ,,Packets,"Packets are modest-sized buffers of data, transmitted as a unit through some shared set of links. Of necessity, Packets need to be prefixed with a header containing delivery information. In the common case known as Datagram forwarding, the header contains a Destination address; headers in networks using so-called Virtual-circuit forwarding contain instead an Identifier for the connection."43.   ,,,"A Local-Area Network, or LAN, is a system consisting of",,,"·       Physical links that are ultimately serial lines, ",,,"·       Common interfacing hardware connecting the hosts to the links, ",,,·       A to make everything work together44.   ,,Transmission Control Protocol,"TCP guarantees the reliable delivery of data, it retransmits each segment if an ACK is not received in a certain period of time. TCP sets this timeout as a function of the RTT it expects between the two ends of the connection. Unfortunately, given the range of possible RTTs between any pair of hosts on the Internet, as well as the variation in RTT between the same two hosts over time, choosing an appropriate timeout value is not that easy. To address this problem, TCP uses an adaptive retransmission mechanism. We now describe this mechanism and how it has evolved over time as the Internet community has gained more experience using TCP."45.   ,,,"The Hamming Code is another popular Error-Correction code; it adds O(log N) additional bits, though if N is large enough for this to be a material improvement over the O(N1/2) performance of 2-D parity then errors must be very infrequent. If we have 8 data bits, let us number the bit positions 0 through 7. We then write each bit’s position as a binary value between 000 and 111; we will call these the position bits of the given data bit"46.   ,,,47.   ,,Assembler file,An Assembler file is a text file. An Assembler reads the source file (MIPS assembly language) and it outputs an object file (MIPS binary machine code) or error report. Well an Assembler is just a translator from MIPS assembler language to binary.48.   ,,Wide Area Network (WAN),"Wide Area Network provides no limit of distance. In most WAN, the subnet consists of two distinct components. Transmission lines, also called circuits or channels, and routers. Transmission lines are used for moving bits between machines, whereas routers are used to connect two or more transmission lines.",,," A WAN provides long distance transmission of data, voice, image and video information over large geographical areas that may comprise a country, a continent or even the whole world. In contrast to LANs (which depend on their own hardware for transmission), WANs may utilize public, leased or private communication devices usually in combination, and span own unlimited number of miles. ",,,A WAN that is wholly owned by a single company is often referred to as an enterprise network.49.   ,,Polling–Based MAC Protocols,"Polling involves the channel control of all workstations in a network. The primary workstation acts like a teacher going down the rows of the classroom asking each student for homework. When one student has answered, the next is given a chance to respond. A polling network contains two classes of workstations, the primary workstation and the multiple secondary workstations connected to it. A buffer that can temporarily store messages is associated with each secondary workstation. When a workstation has information to transmit, the data is passed to the buffer. The frames are held until the central controller polls the workstation."50.   ,,The goal of Network administration,The goal is to keep the network running properly and configuring and managing services that are provided over the network. There are many services that we use regularly. There are some which work in the background enabling other services to run smoothly.51.   ,,The challenges of system administration,System administration is not just about installing operating systems. It is about planning and designing an efficient community of computers so that real users will be able to get their jobs done. That means: ,,,• Designing a network which is logical and efficient. ,,,• Deploying large numbers of machines which can be easily upgraded later. ,,,• Deciding what services are needed. ,,,• Planning and implementing adequate security. ,,,• Providing a comfortable environment for users. ,,,• Developing ways of fixing errors and problems which occur. • Keeping track of and understanding how to use the enormous amount of knowledge which increases every year.52.   ,,Function of packets,"The function of a packet is to carry data from one point to another. Protocols require that packet contain some basic information about their source and their destination and in many cases, protocols require that the packet include a checksum. A checksum is a number that can be used to verify that the packet has been transferred across the network without being corrupted."53.   ,,Token Passing,"The network continuously circulates a special bit pattern known as a token, among all the modes in the network. Each token contains network information, comprising a header, a data field and a trailer. Any mode willing to send a frame has to grass a token first. Now, let us talk about some standards."54.   ,,What is network and system administration,"Network and system administration is a branch of engineering that concerns the operational management of human–computer systems. It is about putting together a network of computers (workstations, PCs and supercomputers), getting them running and then keeping them running in spite of the activities of users who tend to cause the systems to fail. ",,,"A system administrator works for users, so that they can use the system to produce work. However, a system administrator should not just cater for one or two selfish needs, but also work for the benefit of a whole community. Today, that community is a global community of machines and organizations, which spans every niche of human society and culture, thanks to the Internet. It is often a difficult balancing act to determine the best policy, which accounts for the different needs of everyone with a stake in a system. Once a computer is attached to the Internet, we have to consider the consequences of being directly connected to all the other computers in the world."55.   ,,Types of Network,There are basically two types of network based on whether the network contains switching elements or not. These are Point–to–Point network and Broadcast network.,,,"Ø  Point–to–Point Network or Switch Network Point–to–Point networks consist of many connections between individual pairs of machines. To go from the to the source destination, a packet on this type of network may have to first visit one or more intermediate machine routers. When a packet is sent from one router to another intermediate router, the entire packet is stored at each intermediate router, till the output line is free and then forwarded. A subnet using this principle is called Point–to–Point or Packet switched network.",,,"·       Star In a star topology, each device has a dedicated Point–to–Point link only to a central controller, usually called a hub. These devices are not linked to each other. If one device wants to send data to another, it sends to the hub which then relays the data to the other connected devices. In a star, each device needs only one link and one I/O Port to connect it to any number of other devices. This factor makes it easy to install and configure. Far less cabling need to be housed and additions, moves and deletions involve only one connection between that device and the hub. ",,,"·       Tree A tree topology is a variation of a star. As in a star modes in a tree are linked to a central hub that controls the traffic to the network. However, not every device plugs directly into the central hub. The majority of devices connect to a secondary hub that in turn is connected to the central hub.",,,"·        Ring In a ring topology, each device has a dedicated Point–to–Point line configuration only, with the two devices on either side of it. A signal is passed along the ring in one direction from device to device, until it reaches its destination. Each device in the ring incorporates a repeater. When a device receives a signal intended for another device, its repeater regenerates the bits and passes them along.",,,"·       Bus, unlike other topologies, is a multi–point configuration. One long cable acts as a backbone to link all the devices in the network. Advantages of a bus topology include use of installation. A disadvantage includes difficult reconfiguration and fault isolation.",,,"Ø  Broadcast Networks Broadcast networks have a single communication channel that is shared by all the machines on the network. Short messages, called packets, sent by any machine are received by all the others. An address field within the packet specifies for when it is intended. Upon receiving a packet, a machine checks the address field. If the packet is intended for itself, it processes the packet; if the packet is intended for some other machine, it is just ignored."56.   ,,PACKET SWITCHING,"A quite different approach is used in a packet switching network. In this case, it is not necessary to dedicate transmission capacity along a path through the network. Rather, data are sent out in a sequence of small chunks, called packets. Each packet is passed through the network from node to node along some path leading from source to destination. At each node, the entire packet is received, stored briefly, and then transmitted to the next node. Packet switching networks are commonly used for terminal to computer communications."57.   ,,Bridges,"Segmenting a large network with a device has numerous benefits. Among these are reduced collisions (in an Ethernet network), contained bandwidth utilization, and the ability to filter out unwanted packets. However, if the addition of the interconnect device required extensive reconfiguration of stations, the benefits of the device would be outweighed by the administrative overhead required to keep the network running. Bridges were created to allow network administrators to segment their networks transparently. This means that individual stations need not know whether there is a bridge separating them or not. It is up to the bridge to make sure that packets get properly forwarded to their destinations. This is the fundamental principle underlying all of the bridging behaviours. Bridges work at the Data Link Layer of the OSI model. Since bridges work in the Data Link Layer they do not examine the network layer addresses. They just look at the MAC addresses for Ethernet and Token Ring, Token Bus and determine whether or not to forward or ignore a packet."58.   ,,Modem,"This is a device which is used to convert digital signals generated by the computer into an analog signal to be carried by a public access telephone line. It is also the device that converts the analog signal received over a phone line into digital signal usable by the computer. A modem derives it meaning from a modulation, and demodulation is a composite word that refers to two functional units that make up a device. A signal modulator and a signal demodulator. A modulator converts digital signal into an analog signal. A demodulator converts analog signal into digital signal. Modem can be classified into many categories to include the mode of transmission and their techniques, as well as by the application features they contain and the type of lines they are built to service."59.   ,,Asynchronous Transfer Mode (ATM),"Asynchronous Transfer Mode (ATM) is a form of data transmission that allows voice, video and data to be sent along the same network. In contrast to ATM, in the past, voice, video and data were transferred using separate networks. For example, voice was transmitted over the phone, video over cable networks, and data over an internetwork. ATM is the ultimate culmination of all the developments in switching and transmission in the last twenty years and has the best of circuit switching and packet switching (discussed, in the previous block). ",,,"Asynchronous Transfer Mode (ATM) is a technology that has its history in the development of broadband ISDN in the 1970s and 1980s. In this unit, first we will have a re–look at different types of switching techniques (technologies) and then we will examine how ATM is compatible with the existing technologies and then compare the architectural difference between ATM and the OSI model and finally, spend some time on how ATM protocol works."60.   ,,Circuit Switching,"This was the first type of data transfer mechanism used. Circuit switching is used in the telephone networks to transmit voice and data signals. In a synchronous transmission, which involves transmission of voice, a synchronized connection must be made between the sender and receiver because there must be a constant time interval between each successive bit, character, or event. To enable synchronized transmission, circuit switching establishes a dedicated connection between the sender and the receiver involved in the data transfer over the network. As a result, the connection consumes network capacity whether or not there is an active transmission taking place; for example, the network capacity is used even when a caller is put on hold. For different applications, utilization of the line can vary enormously. However, there is little delay and effective transparency for the user. It is very efficient for Constant Bit Rate (CBR)."61.   ,,The ATM Network,An ATM networks consist of a set of ATM switches interconnected by point–to–point ATM links or interfaces. ATM switches support three kinds of interfaces: ,,,·       User–Network Interfaces (UNI) ,,,·       Network–Node Interfaces (NNI),,,·       Inter–Carrier Interface (ICI)62.   ,,Type of Connection,A network is two or more devices connected through links. A link is a communications pathway that transfers data from one device to another. There are two possible types of connections: point-to-point and multipoint. ,,,"·       Point-to-Point: A point-to-point connection provides a dedicated link between two devices. The entire capacity of the link is reserved for transmission between those two devices. Most point-to-point connections use an actual length of wire or cable to connect the two ends, but other options, such as microwave or satellite links, are also possible. When you change television channels by infrared remote control, you are establishing a point-to-point connection between the remote control and the television's control system. ",,,"·       Multipoint: A multipoint (also called multi-drop) connection is one in which more than two specific devices share a single link. In a multipoint environment, the capacity of the channel is shared, either spatially or temporally. If several devices can use the link simultaneously, it is a spatially shared connection. If users must take turns, it is a timeshared connection."63.   ,,Physical Topology,"The term physical topology refers to the way in which a network is laid out physically. Two or more devices connect to a link; two or more links form a topology. The topology of a network is the geometric representation of the relationship of all the links and linking devices (usually called nodes) to one another. There are four basic topologies possible: mesh, star, bus, and ring"64.   ,,Switching,"A network is a set of connected devices. Whenever we have multiple devices, we have the problem of how to connect them to make one-to-one communication possible. One solution is to make a point-to-point connection between each pair of devices (a mesh topology) or between a central device and every other device (a star topology). These methods, however, are impractical and wasteful when applied to very large networks. ",,,"The number and length of the links require too much infrastructure to be cost-efficient, and the majority of those links would be idle most of the time. ",,,"A better solution is switching. A switched network consists of a series of interlinked nodes, called switches. Switches are devices capable of creating temporary connections between two or more devices linked to the switch. In a switched network, some of these nodes are connected to the end systems (computers or telephones, for example). Others are used only for routing. Figure shows a switched network."65.   ,,Circuit-Switched Networks,"A circuit-switched network consists of a set of switches connected by physical links. A connection between two stations is a dedicated path made of one or more links. However, each connection uses only one dedicated channel on each link. Each link is normally divided into n channels by using FDM or TDM.",,," In circuit switching, the resources need to be reserved during the setup phase; the resources remain dedicated for the entire duration of data transfer until the teardown phase."66.   ,,Advantages of Distributed processing,Advantages of Distributed processing are: ,,,·       Security/ Encapsulation ,,,·       Distributed data bases ,,,·       Faster problem solving ,,,·       Security through Redundancy ,,,·       Collaborative processing67.   ,,Integrated Services Digital Network (ISDN),"ISDN was developed by ITU- T in 1976.It is a set of protocols that combines digital telephony and data transport services. The whole idea is to digitize the telephone network to permit the transmission of audio, video, and text over existing telephone lines. The goal of isdn is to form a wide network that provides universal end –to – end connectivity over digital media. This can be done by integrating all of the separate transmission services into one without adding links or subscriber lines."68.   ,,Hamming codes,"Hamming codes provide another method for error correction. Error bits, called Hamming bits, are inserted into message bits at random locations. It is believed that the randomness of their locations reduces the odds that these Hamming bits themselves would be in error. This is based on a mathematical assumption that because there are so many more message bits compared with Hamming bits, there is a greater chance for a message bit to be in error than for a Hamming bit to be wrong. Determining the placement and binary value of the Hamming bits can be implemented using hardware, but it is often more practical to implement them using software. The number of bits in a message (M) are counted and used to solve the following equation to determine the number of Hamming bits (H) to be used: ",,,2H ≥ M + H + 1,,,"Once the number of Hamming bits is determined, the actual placement of the bits into the message is performed. It is important to note that despite the random nature of the Hamming bit placements, the exact sample placements must be known and used by both the transmitter and receiver. Once the Hamming bits are inserted into their positions, the numerical values of the bit positions of the logic 1 bits in the original message are listed. The equivalent binary numbers of these values are added in the same manner as used in previous error methods by discarding all carry results. The sum produced is used as the states of the Hamming bits in the message. The numerical difference between the Hamming values transmitted and that produced at the receiver indicates the bit position that contains a bad bit, which is then inverted to correct it."69.   ,,Piggy backing,"In most practical situations there is a need of transmitting data in both directions. This can be achieved by full duplex transmission. If this is done we have two separate physical circuits each with a “forward” and “reverse” channel. In both cases, the reverse channel is almost wasted. To overcome this problem a technique called piggy backing is used. ",,,The technique of temporarily delaying outgoing acknowledgements so that they can be hooked onto the next outgoing data frame is known as piggy backing. ,,,"However, piggybacking introduces a complication not present with separate acknowledgements. How long should the data link layer wait longer than the sender‘s timeout period, the frame will be retransmitted, defeating the whole purpose of having acknowledgements. Of course, the data link layer cannot foretell the future, so it must resort to some ad hoc scheme, such as waiting a fixed number of milli seconds. If a new packet arrives quickly, the acknowledgement is piggy backed onto it; otherwise, if no new packet has arrived by the end of this time period, the data link layer just sends a separate acknowledgement frame."70.   ,,Internetwork protocol,"At the network layer, TCP/IP supports the internetwork protocol .IP, in turn, contains four supporting protocols: ARP, RARP, ICMP, and IGMP. ",,,"IP is the transmission mechanism used by the TCP/IP protocols. It is an un-reliable and connectionless datagram protocol – a best effort delivery service. This is like a post office service. The post office does its best to deliver the mail but does not always succeed. If an unregistered letter is lost. It is up to the sender or would recipient to discover the loss and rectify the problem. The post office itself does not keep track of every letter and cannot notify a sender of loss or damage. An example of a situation similar to pairing IP with a protocol that contains reliability functions is a self-addressed, stamped postcard included in a letter mailed through the post office. When the letter is delivered, the receiver mails the postcard back to the sender to indicate success. If the sender never receives the postcard, he or she assumes the letter was lost and sends out another copy. IP transports data in packets called Datagrams, each of which is transported separately. Datagrams may travel along different routes and may arrive out of sequence or duplicated. IP does not create virtual circuits for delivery."71.   ,,Security Attacks,Attacks on the security of a computer system or network are best characterized by viewing the function of the computer system as providing information. ,,,There are four general categories of attack: ,,,"· Interruption: An asset of the system is destroyed or becomes unavailable or unusable. This is an attack on availability. Examples include destruction of a piece of hardware, such as a hard disk, the cutting of a communication line, or the disabling of the file management system. ",,,"· Interception: An unauthorized party gains access to an asset. This is an attack on confidentiality. The unauthorized party could be a person, a program, or a computer. Examples include wiretapping to capture data in a network, and the illicit copying of files or programs. ",,,"· Modification: An unauthorized party not only gains access to but tampers with an asset. This is an attack or integrity. Examples include changing values in a data file, altering a program so that it performs differently, and modifying the content of messages being transmitted in a network. ",,,· Fabrication: An unauthorized party inserts counterfeit objects into the system. This is an attack on authenticity. Examples include the insertion of spurious messages in a network or the addition of records to a file.72.   ,,Encapsulation,"Encapsulation is the process of encoding data for transmitting it across the network. Once a packet is created as described previously, in order for the packet to be transmitted to its final destination, it may need to use a protocol in addition to the one that it is currently using. A header and CRC are then added to the newly created packet. This packet is an encapsulated packet. Figure 1 illustrates an encapsulated packet."73.   ,,The OSI model,"The Open System Interconnection (OSI) reference model was developed by the International Standards Organization (ISO) and provides a framework for protocol development. By implementing a communication protocol that adheres to the OSI model, systems developed by different manufacturers are able to communicate. The tasks that must be performed to enable machines to communicate in an effective and efficient manner are incorporated within a seven-layer hierarchy, as indicated in figure 3. Although the protocols detailed within this reference 0 model are seldom used, the model provides us with an excellent conceptual framework for understanding the tasks performed by the various software layers. Below we briefly summarize aspects of the functionality of the various layers."74.   ,,User Data Protocol (UDP),"User Data Protocol (UDP) The internet protocol suite also supports a connectionless transport protocol, UDP (User Data Protocol). UDP provides a way for applications to send encapsulated raw IP datagrams and send them without having to establish a connection. Many client–server applications that have one request and one response use UDP rather than go through the trouble of establishing and later releasing a connection. A UDP segment consists of an 8–byte header followed by the data. The two ports serve the same function as they do in TCP: to identify the end–points within the source and destination machines. The UDP length field includes the 8–byte header and the data. The UDP checksum includes the same format pseudo– header, the UDP header, and the UDP data, padded out to an even number of bytes if need be. It is optional and stored as 0 if not computed."75.   ,,The Domain Name System (DNS),"DNS is a scheme for assigning meaningful high-level name to a large set of machines, and discusses a mechanism that maps between high-level machine names and IP addresses. It considers both the translation from high-level name to IP addresses and the translation from IP addresses to high-level machines names. It has been used to assign machine names throughout the global Internet. It uses a geographically distributed set of servers to map names to addresses, the implementation of the name mapping mechanism provides a large scale example of the client sever paradigm. In a TCP/IP internet, hierarchical machine names are assigned according to the structure of organizations that obtain authority for parts of the namespace, not necessarily according to the structure of the physical network interconnections."76.   ,,Electronic Mail,"This is the most widely used service facilitating users to send and receive messages electronically in a store and forward manner. Different E–mail standards, viz., SMTP, UUCP and X400 Message Handling system, are supported on ERNET.",,, Electronic Mail is a system whereby a computer user can exchange messages with other computer users or group of users via a communications network. ,,,"The backbone of an electronic mail system is a communication network that connects remote terminals to a central system or a local area network that interconnects personal computers. Users can send mails to a single recipient or they can broadcast it to any number of selected users on the systems. When multi–tasking personal computer and workstation are used, mail can be delivered to users while they are working on something else. Otherwise, users have to interrogate their mail boxes in a central system, or file server.",,," Many users first encounter computer networks when they send or receive electronic mail to or from a remote site. E–mail is the most widely used application service. Indeed, many computer users access networks only through electronic mail. ",,,"E–mail is popular because it offers a fast, convenient method of transferring information. E–mail can accommodate small notes or large voluminous memos with a single mechanism. It should not surprise you to learn that more users send files with electronic mail than with file transfer protocols."77.   ,,WWW (World Wide Web),"The World Wide Web is a system for linking up hypertext documents. Each document is a page written in HTML, possible with hyperlinks to other documents. A browser can display a document by establishing a TCP connection to its server, asking for the document, and then closing the connection. When a hyperlink is selected by the user, that document can also be fetched in the same way. In this manner, documents all over the world are linked together in a giant web. Some facts about WWW: ",,,· Fastest growing discovery and retrieval system,,,"· Presently 10,000 servers, growing at an astounding rate ",,,"· Retrieve “hypermedia” documents, with text, graphics, audio, video, and links to other hypermedia documents. ",,,· A navigational system based on “hyperlink” ,,,"· State–less interaction between client and server, conforming to “http” protocol."78.   ,,Remote Procedure Call (RPC),"The designers chose to build three independent pieces; the NFS protocol itself, a general purpose Remote Procedure Call (RPC) mechanism, and a general purpose External Data Representation (XDR). Their intent was to separate the three to make it possible to use RPC and XDR in other software, including application programs as well as other protocols. For example, a programmer can divide a program into a client side and a server side that use RPC as the chief communication mechanism can one of the client sides, the programmer designates some procedures as remote, forcing the compiler to incorporate RPC code into those procedures. On the server side, the programmer implements the desired procedures and uses other RPC facilities to declare them to be part of a server. When the executing client program calls one of the remote procedures, RPC automatically collects values for argument, from a message, sends the message to the remote server, awaits a response, and stores returned values in the designated arguments. In essence, communication with the remote server occurs automatically as a side– effect of a remote call. The RPC mechanism hides all the details of protocols, making it possible for programmers who know little about the underlying communication protocols to write distributed programs.",,,79.   ,,File Transfer Protocol (FTP),FTP (File Transfer Protocol) is the primary method of transferring files over the Internet. “FTP” transfers files to and from a remote network site. Some sites maintain Anonymous accounts on the system for retrieval of public domain software stored on the system. ,,,"The ftp protocol is used to access files by FTP, the Internet’s file transfer protocol. FTP has been around more than two decades and is well entrenched. Numerous FTP servers all over the world allow people anywhere on the internet to log in and download whatever files have been placed on the FTP server. The web does not change this; it just makes obtaining files by FTP easier, as FTP has a somewhat arcane interface."80.   ,,Telnet,"Telnet is a program that allows you to establish a virtual terminal connection between two machines using TCP/IP. For this, you must have its internet address or host name of computer.",,,81.   ,SOFTWARE ENGINEERING,Software Engineering,"Software engineering is an engineering branch associated with development of software product using well-defined scientific principles, methods and procedures. The outcome of software engineering is an efficient and reliable software product."82.   ,,Paradigm ,"This Paradigm is known as Software Engineering Paradigms; where all the engineering concepts pertaining to the development of software are applied. It includes various researches and requirement gathering which helps the software product to build. It consists of Requirement gathering, Software design, and Programming"83.   ,,Big Bang Model,"Big Bang Model is the simplest model in its form. It requires little planning, lots of programming and lots of funds. This model is conceptualized around the big bang of universe. As scientists say that after big bang lots of galaxies, planets, and stars evolved just as an event. Likewise, if we put together lots of programming and funds, you may achieve the best software product."84.   ,,Software Project,"A Software Project is the complete procedure of software development from requirement gathering to testing and maintenance, carried out according to the execution methodologies, in a specified period of time to achieve intended software product."85.   ,,Software Project Manager,A software project manager is a person who undertakes the responsibility of executing the software project. Software project manager is thoroughly aware of all the phases of SDLC that the software would go through. The project manager may never directly involve in producing the end product but he controls and manages the activities involved in production.86.   ,,Project Manager,"A Project Manager closely monitors the development process, prepares and executes various plans, arranges necessary and adequate resources, maintains communication among all team members in order to address issues of cost, budget, resources, time, quality and customer satisfaction."87.   ,,Project Scheduling,"Project Scheduling in a project refers to roadmap of all activities to be done with specified order and within time slot allotted to each activity. Project managers tend to define various tasks and project milestones and then arrange them keeping various factors in mind. They look for tasks like in critical path in the schedule, which are necessary to complete in specific manner (because of task interdependency) and strictly within the time allocated. Arrangement of tasks which lies out of critical path are less likely to impact over all schedule of the project."88.   ,,Effective Communication,"Effective Communication plays vital role in the success of a project. It bridges gaps between Client and the Organization, among the Team members as well as other Stake Holders in the project such as Hardware Suppliers."89.   ,,Modularization,"Modularization is a technique to divide a software system into multiple discrete and independent modules, which are expected to be capable of carrying out task(s) independently. These modules may work as basic constructs for the entire software. Designers tend to design modules such that they can be executed and/or compiled separately and independently"90.   ,,Data Flow Diagram (DFD),"Data Flow Diagram (DFD) is a graphical representation of flow of data in an Information System. It is capable of depicting incoming data flow, outgoing data flow, and stored data. The DFD does not mention anything about how data flows through the system. There is a prominent difference between DFD and Flowchart. The flowchart depicts flow of control in program modules. DFDs depict flow of data in the system at various levels. It does not contain any control or branch elements."91.   ,,Software Development Life Cycle (SDLC),"The software development life cycle (SDLC) is the process for planning, creating, testing, and deploying an information system. There are different approaches to break down the work when developing software systems. Conceptually, each model provides specific guidance to the sequencing and repetition of life cycle activities to deliver high-quality software systems."92.   ,,Software Modeling ,"Many believe that good design is fundamental to creating successful software. The first step in software creation is to gather requirements. Notations, such as UML, allow us to articulate complex ideas succinctly and precisely. Designing software requires the use of certain industry-standard design tools, and mastery of them is essential to becoming a capable software engineer.",,,"This unit will introduce you to UML, a standardized general-purpose modeling language for creating visual models of object-oriented software. This unit aims to give you a comprehensive understanding of UML, the five fundamental artifacts of UML, and modeling concepts, as well as the modeling concepts' relationships to the terms system, model, and view.",,,93.   ,,Software Requirements Gathering,"Requirements gathering requires the software engineer (in this case, a business analyst) to interact with the stakeholders, including customers and users, to gather/collect information about what the software system being developed needs to do. There is also the situation where vendors are subcontracted to develop all, or some components, of the software systems and/or develop the hardware that the software will run on. In this case, the vendors bid on the subcontract by providing a proposal in response to a request for proposals. In this unit, you will learn the data/information types, data collection techniques, and data collection and application types.",,,94.   ,,Project management,"Project management in a software engineering environment is unique because of the technical aspects of a software project. The project manager's role is different from that of the software engineer's. While software engineers are generally accountable for the technical aspects of a project, the project manager is accountable for organizational aspects.",,,"As you review the materials of the unit, try to connect this unit with what you have already learned about the software development life cycle. You will see that the success of an SDLC depends on people, process, and product. Project management is the glue that holds these aspects together.",,,95.   ,,Who is a Software Engineer?,"A software engineer is an individual who applies the principles of software engineering to the design, development, testing, and evaluation of the software and systems in order to meet with client‘s requirements. He/she fully designs software, tests, debugs and maintains it. Software engineer needs knowledge of varieties of computer programming languages and applications; to enable him cope with the varieties of works before him. In view of this, he can sometimes be referred to as a computer programmer."96.   ,,What is Software Crisis?,"The term software crisis was used in the early days of software engineering. It was used to describe the impact of prompt increases in computer power and the difficulty of the problems which could be tackled. In essence, it refers to the difficulty of writing correct, understandable, and verifiable computer programs. The sources of the software crisis are complexity, expectations, and change. Conflicting requirements has always hindered software development process. For instance, while users demand a large number of features, customers generally want to minimise the amount they must pay for the software and the time required for its development. F. L. Bauer coined the term ""software crisis"" at the first NATO Software Engineering Conference in 1968 at Garmisch, Germany. The term was used early in Edsger Dijkstra's 1972 ACM Turing Award Lecture:"97.   ,,Requirements Management,"Requirements Management is the all-inclusive process that includes all aspects of software requirements analysis and as well ensures verification, validation and traceability of requirements. Effective requirements management practices assure that all system requirements are stated unmistakably, that omissions and errors are corrected and that evolving specifications can be included later in the project lifecycle."98.   ,,Definition of software design,"A software design is a meaningful engineering representation of some software product that is to be built. A design can be traced to the customer's requirements and can be assessed for quality against predefined criteria. In the software engineering context, design focuses on four major areas of concern: data, architecture, interfaces and components. ",,,"The design process is very important. As a laborer, for example one would not attempt to build a house without an approved blueprint so as not to risk the structural integrity and customer satisfaction. In the same way, the approach to building software products is no unlike. The emphasis in design is on quality. It is pertinent to note that, this is the only phase in which the customer‘s requirements can be precisely translated into a finished software product or system. As such, software design serves as the foundation for all software engineering steps that follow regardless of which process model is being employed."99.   ,,What is Modularity?,"Modularity is a general systems concept which is the degree to which a system‘s components may be separated and recombined. It refers to both the tightness of coupling between components, and the degree to which the “rules” of the system architecture enable (or prohibit) the mixing and matching of components. ",,,"The concept of modularity in computer software has been promoted for about five decades. In essence, the software is divided into separately names and addressable components called modules that are integrated to satisfy problem requirements. It is important to note that a reader cannot easily understand large programs with a single module. The number of variables, control paths and sheer complexity make understanding almost impossible. As a result a modular approach will allow for the software to be intellectually manageable. However, it is important to note that software cannot be subdivided indefinitely so as to make the effort required to understand or develop it negligible. This is because the more the number of modules, the less the effort to develop them."100.                   ,,Module Interconnection Languages,"Module interconnection languages (MILs) provide formal grammar constructs for deciding the various module interconnection specifications required to assemble a complete software system. MILs enable the separation between programming-in-thesmall and programming-in-the-large. Coding a module represents programming in the small, while assembling a system with the help of a MIL represents programming in the large. An example of MIL is MIL-75."101.                   ,,Top-Down Design,"Top-down is a programming style, the core of traditional procedural languages, in which design begins by specifying complex pieces and then dividing them into successively smaller pieces. Finally, the components are precise enough to be coded and the program is written. It is the exact opposite of the bottom-up programming approach which is common in object-oriented languages such as C++ or Java. The method of writing a program using top-down approach is to write a main procedure that names all the major functions it will need. After that the programming team examines the requirements of each of those functions and repeats the process. These compartmentalized sub-routines finally will perform actions so straightforward they can be easily and concisely coded. The program is done when all the various sub-routines have been coded."102.                   ,,Bottom-up approach,"In a bottom-up approach the individual base elements of the system are first specified in great detail. These elements are then connected together to form bigger subsystems, which are linked, sometimes in many levels, until a complete top-level system is formed. This strategy often resembles a ""seed"" model, whereby the beginnings are small, but eventually grow in complexity and completeness. ",,,"Object-oriented programming (OOP) is a programming paradigm that uses ""objects"" to design applications and computer programs.",,,"This bottom-up approach has one drawback. We need to use a lot of perception to decide the functionality that is to be provided by the module. This approach is more suitable if a system is to be developed from existing system, because it starts from some existing modules. Modern software design approaches usually mix both top-down and bottom-up approaches."103.                   ,,Definition of Pseudo code,"Pseudo-code is a non-formal language, a way to create a logical structure, describing the actions, which will be executed by the application. Using pseudo-code, the developer shows the application logic using his local language, without applying the structural rules of a specific programming language. The big advantage of the pseudo-code is that the application logic can be easily comprehended by any developer in the development team. In addition, when the application algorithm is expressed in pseudo-code, it is very easy to convert the pseudo-code into real code (using any programming language)."104.                   ,,Definition of Programming Environment,"Programming environments gives the basic tools and Application Programming Interfaces, or APIs, necessary to construct programs. Programming environments help the creation, modification, execution and debugging of programs. The goal of integrating a programming environment is more than simply building tools that share a common data base and provide a consistent user interface. Altogether, the programming environment appears to the programmer as a single tool; there are no firewalls separating the various functions provided by the environment."105.                   ,,Types of Programming Environment,Software development tools can be roughly divided into the following categories:,,,· performance analysis tools ,,,· debugging tools ,,,· static analysis and formal verification tools 66 ,,,· correctness checking tools ,,,· memory usage tools ,,,· application build tools ,,,· integrated development environment106.                   ,,Integrated development environments,"Integrated development environments (IDEs) merge the features of many tools into one complete package. They are usually simpler and make it easier to do simple tasks, such as searching for content only in files in a particular project. IDEs are often used for development of enterprise-level applications. Some examples of IDEs are: · Delphi ",,,· C++ Builder (CodeGear) ,,,· Microsoft Visual Studio ,,,· EiffelStudio ,,,· GNAT Programming Studio ,,,· Xcode ,,,· IBM Rational Application Developer ,,,· Eclipse ,,,· NetBeans ,,,· IntelliJ IDEA ,,,· WinDev ,,,· Code::Blocks ,,,· Lazarus107.                   ,,What is CASE Tools?,"CASE tools are a class of software that automates many of the activities involved in various life cycle phases. For example, when establishing the functional requirements of a proposed application, prototyping tools can be used to develop graphic models of application screens to assist end users to visualize how an application will look after development. Subsequently, system designers can use automated design tools to transform the prototyped functional requirements into detailed design documents. Programmers can then use automated code generators to convert the design documents into code. Automated tools can be used collectively, as mentioned, or individually. For example, prototyping tools could be used to define application requirements that get passed to design technicians who convert the requirements into detailed designs in a traditional manner using flowcharts and narrative documents, without the assistance of automated design software. ",,,"It is the scientific application of a set of tools and methods to a software system which is meant to result in high-quality, defect-free, and maintainable software products. It also refers to methods for the development of information systems together with automated tools that can be used in the software development process."108.                   ,,Toolkits,"Toolkits are loosely integrated collections of products easily extended by aggregating different tools and workbenches. Typically, the support provided by a toolkit is limited to programming, configuration management and project management. And the toolkit itself is environments extended from basic sets of operating system tools, for example, the Unix Programmer's Work Bench and the VMS VAX Set. In addition, toolkits' loose integration requires user to activate tools by explicit invocation or simple control mechanisms. The resulting files are unstructured and could be in different format, therefore the access of file from different tools may require explicit file format conversion. However, since the only constraint for adding a new component is the formats of the files, toolkits can be easily and incrementally extended."109.                   ,,Language-centered,"The environment itself is written in the programming language for which it was developed, thus enable users to reuse, customize and extend the environment. Integration of code in different languages is a major issue for language-centered environments. Lack of process and data integration is also a problem. The strengths of these environments include good level of presentation and control integration. Interlisp, Smalltalk, Rational, and KEE are examples of language-centered environments."110.                   ,,Fourth generation,"Fourth generation environments were the first integrated environments. They are sets of tools and workbenches supporting the development of a specific class of program: electronic data processing and business-oriented applications. In general, they include programming tools, simple configuration management tools, document handling facilities and, sometimes, a code generator to produce code in lower level languages. Informix 4GL and Focus fall into this category."111.                   ,,System Model,Shows the relationships between the system components and the system and its environment. An abstract data model should also be described if appropriate to the type of system.112.                   ,,Benefits of Spiral Development,v  Delivers initial value early ,,,·       Mitigates risk of failure ,,,·       Focus on high-priority functionality ,,,v  Frequent requirements refinement ,,,·       Uses feedback from one iteration to refine requirements for the next ,,,·       Mitigates impact of change ,,,v  Note: the Spiral model is driven by uncertainty and change ,,,·       A theme of the whole course113.                   ,, Phases of Agile Model,Phases of Agile Model includes the following:,,,1.     Requirements gathering,,,2.     Design the requirements,,,3.     Construction/ iteration,,,4.     Testing/ Quality assurance,,,5.     Deployment,,,6.     Feedback,,,"1.     Requirements gathering: In this phase, you must define the requirements. You should explain business opportunities and plan the time and effort needed to build the project. Based on this information, you can evaluate technical and economic feasibility. ",,,"2.     Design the requirements: When you have identified the project, work with stakeholders to define requirements. You can use the user flow diagram or the high-level UML diagram to show the work of new features and show how it will apply to your existing system. ",,,"3.     Construction/ iteration: When the team defines the requirements, the work begins. Designers and developers start working on their project, which aims to deploy a working product. The product will undergo various stages of improvement, so it includes simple, minimal functionality. ",,,"4.     Testing: In this phase, the Quality Assurance team examines the product's performance and looks for the bug. ",,,"5.     Deployment: In this phase, the team issues a product for the user's work environment. ",,,"6.     Feedback: After releasing the product, the last step is feedback. In this, the team receives feedback about the product and works through the feedback."114.                   ,,CASE Risk,Common CASE risks and associated controls include: ,,,"·       Inadequate Standardization: Linking CASE tools from different vendors (design tool from Company X, programming tool from Company Y) may be difficult if the products do not use standardized code structures and data classifications. File formats can be converted, but usually not economically. Controls include using tools from the same vendor, or using tools based on standard protocols and insisting on demonstrated compatibility. Additionally, if organizations obtain tools for only a portion of the development process, they should consider acquiring them from a vendor that has a full line of products to ensure future compatibility if they add more tools. ",,,"·        Unrealistic Expectations: Organizations often implement CASE technologies to reduce development costs. Implementing CASE strategies usually involves high start-up costs. Generally, management must be willing to accept a long-term payback period. Controls include requiring senior managers to define their purpose and strategies for implementing CASE technologies. ",,,"·       Quick Implementation: Implementing CASE technologies can involve a significant change from traditional development environments. Typically, organizations should not use CASE tools the first time on critical projects or projects with short deadlines because of the lengthy training process. Additionally, organizations should consider using the tools on smaller, less complex projects and gradually implementing the tools to allow more training time. ",,,"·       Weak Repository Controls : Failure to adequately control access to CASE repositories may result in security breaches or damage to the work documents, system designs, or code modules stored in the repository. Controls include protecting the repositories with appropriate access, version, and backup controls."115.                   ,,HIPO Diagrams,"The HIPO (Hierarchy plus Input-Process-Output) technique is a tool for planning and/or documenting a computer program. A HIPO model consists of a hierarchy chart that graphically represents the program‘s control structure and a set of IPO (Input-ProcessOutput) charts that describe the inputs to, the outputs from, and the functions (or processes) performed by each module on the hierarchy chart."116.                   ,,Components of HIPO,"A completed HIPO package has two parts. A hierarchy chart is used to represent the topdown structure of the program. For each module depicted on the hierarchy chart, an IPO (Input-Process-Output) chart is used to describe the inputs to, the outputs from, and the process performed by the module.",,,·       The hierarchy chart It summarises the primary tasks to be performed by an interactive inventory program. Figure 7 shows one possible hierarchy chart (or visual table of contents) for that program. Each box represents one module that can call its subordinates and return control to its higher-level parent.,,,·       The IPO charts An IPO chart is prepared to document each of the modules on the hierarchy chart.117.                   ,,What is Compatibility Testing?,"Software testing comes in different types. Compatibility testing is one of the several types of software testing which can be carried out on a system that is develop based on certain yardsticks and which has to perform definite functionality in an already existing setup/environment. Many things are decided n compatibility of a system/application being developed with, for example, other systems/applications, OS, Network. They include the use of the system/application in that environment, demand of the system/application etc. On many occasions, the reason while users prefer not to go for an application/system cannot be unconnected with it non-compatibility of such application/system with any other system/application, network, hardware or OS they are already using. This explains the reason why the efforts of developers may appear to be in vain. Compatibility testing can also be used to certify compatibility of the system/application/website built with various other objects such as other web browsers, hardware platforms, users, operating systems etc. It helps to find out how well a system performs in a particular environment such as hardware, network; operating system etc. Compatibility testing can be performed manually or with automation tools."118.                   ,,The Computer Keyboard,"A computer keyboard is identical to the conventional typewriter keyboard. However, it has more keys than the typewriter keyboard. A computer keyboard can be a dummy type or intelligent type. A computer keyboard is considered to be intelligent if, in addition to performing the routine functions characteristic of a typewriter keyboard, it can initiate a series of actions for a computer to carry out by mere pressing a key or combination of two or more keys. Thus, an intelligent computer keyboard has a set of keys which, when one of them is pressed, the computer can be made to carry out a specific function. For example, the pressing of a key may cause the computer to display a menu list from which the user may be prompted to select one."119.                   ,,Sub-disciplines of Software engineering,Software engineering can be divided into ten sub-disciplines. They are as follows: ,,,"·       Software requirements: The elicitation, analysis, specification, and validation of requirements for software. ",,,"·       Software design: Software Design consists of the steps a programmer should do before they start coding the program in a specific language. It is usually done with Computer-Aided Software Engineering (CASE) tools and use standards for the format, such as the Unified Modeling Language (UML). ",,,·       Software development: It is construction of software through the use of programming languages. ,,,·       Software testing Software Testing is an empirical investigation conducted to provide stakeholders with information about the quality of the product or service under test. ,,,·       Software maintenance: This deals with enhancements of Software systems to solve the problems the may have after being used for a long time after they are first completed. ,,,·       Software configuration management: is the task of tracking and controlling changes in the software. Configuration management practices include revision control and the establishment of baselines. ,,,·       Software engineering management: The management of software systems borrows heavily from project management.,,,"·       Software development process: A software development process is a structure imposed on the development of a software product. There are several models for such processes, each describing approaches to a variety of tasks or activities that take place during the process. ",,,"·       Software engineering tools, (CASE which stands for Computer Aided Software Engineering) CASE tools are a class of software that automates many of the activities involved in various life cycle phases. ",,,·       Software quality: The totality of functionality and features of a software product that bear on its ability to satisfy stated or implied needs.120.                   ,,Goals,"Stated requirements when they are initially specified for systems are usually incomplete. Apart from accomplishing these stated requirements, a good software system must be able to easily support changes to these requirements over the system's life. Therefore, a major goal of software engineering is to be able to deal with the effects of these changes. ",,,The software engineering goals include: ,,,·       Maintainability: Changes to software without increasing the complexity of the original system design should be possible. ,,,"·       Reliability: The software should be able to prevent failure in design and construction as well as recover from failure in operation. In other words, the software should perform its intended function with the required precision at all times. ",,,·       Efficiency: The software system should use the resources that are available in an optimal manner. ,,,"·       Understand ability: The software should accurately model the view the reader has of the real world. Since code in a large, long-lived software system is usually read more times than it is written, it should be easy to read at the expense of being easy to write, and not the other way around."121.                   ,ALGORITHM,An Algorithm,"An Algorithm is any well-defined computational procedure that takes some value, or set of values, as input and produces some value, or set of values, as output. An Algorithm is thus a Sequence of computational steps that transform the Input into the Output."122.                   ,,Data structure,"A Data Structure is a way to store and organize data in order to facilitate access and modifications. No single data structure works well for all purposes, and so it is important to know the strengths and limitations of several of them."123.                   ,,Analyzing an algorithm,"Analyzing an Algorithm has come to mean predicting the resources that the algorithm requires. Occasionally, resources such as memory, communication bandwidth, or computer hardware are of primary concern, but most often it is computational time that we want to measure. Generally, by analyzing several candidate algorithms for a problem, we can identify a most efficient one. Such analysis may indicate more than one viable candidate, but we can often discard several inferior algorithms in the process."124.                   ,,A function,"A function ƒ(n) is monotonically increasing if m ≤ n implies ƒ(m)≤ ƒ(n). Similarly, it is monotonically decreasing if m ≤ n implies ƒ(m) ≥ ƒ(n). A ƒ(n) is strictly increasing if m < n implies ƒ(m) < ƒ(n) and strictly decreasing if m < n implies ƒ(n) > ƒ(n)."125.                   ,,An Algorithm ,"An algorithm is a procedure used for solving a problem or performing a computation. Algorithms act as an exact list of instructions that conduct specified actions step by step in either hardware- or software-based routines. Algorithms are widely used throughout all areas of IT. In mathematics, computer programming and computer science, an algorithm usually refers to a small procedure that solves a recurrent problem. Algorithms are also used as specifications for performing data processing and play a major role in automated systems. An algorithm could be used for sorting sets of numbers or for more complicated tasks, such as recommending user content on social media. Algorithms typically start with initial input and instructions that describe a specific computation. When the computation is executed, the process produces an output."126.                   ,,Lung cancer,"Lung cancer is an unpreventable disease whose early detection is essential for patient survival. Several existing models and approaches for predicting high-risk lung cancer patients have been developed but despite these advancements, there is a need for a more comprehensive and holistic approach that considers a wide range of factors to provide a well-rounded risk assessment by including environmental exposures, lifestyle choices, and emerging biomarkers. This research aims to develop a predictive model that will accurately and efficiently identify high-risk Lung cancer patients using logistic regression, deep learning models and explainable AI. We intend to combine data that are publicly available from sources such as TCGA, CDC, WHO, NIH Data Repositories etc. with radiological images and laboratory test results obtained from Lagos State Teaching Hospital. Python library, pydicom will be used for feature extraction. Confusion matrix and associated classification metrics will be used for the model evaluation.",,,127.                   ,,Brute-force Approach,"This strategy is characterised by a lack of sophistication in terms of their approach to the solution. It typically takes the most direct or obvious route, without attempting to minimise the number of operations required to compute the solution. Brute-force approach is considered quite often in the course of searching. In a searching problem, we are required to look through a list of candidates in an attempt to find a desired object. In many cases, the structure of the problem itself allows us to eliminate a large number of the candidates without having to actually search through them. As an analogy, consider the problem of trying to find a frozen pie in an unfamiliar grocery store. You would immediately go to the frozen food aisle, without bothering to look down any of the other aisles. Thus, at the outset of your search, you would eliminate the need to search down most of the aisles in the store. Brute force approach, however, ignores such possibilities and naively searches through all candidates in an attempt to find the desired object. This approach is otherwise known as exhaustive search."128.                   ,,Divide-and-conquer Approach,"In the divide and conquer strategy, a problem is solved recursively by applying three steps at each level of the recursion: Divide, conquer, and combine.",,,"Ø  Divide: “Divide” is the first step of the divide and conquer strategy. In this step the problem is divided into smaller sub-problems until it is small enough to be solved. At this step, sub-problems become smaller but still represent some part of the actual problem. As stated above, recursion is used to implement the divide and conquer algorithm. A recursive algorithm calls itself with smaller or simpler input values, known as the recursive case. So, when the divide step is implemented, the recursive case is determined which will divide the problem into smaller subproblems. Then comes the “conquer” step where we straightforwardly solve the sub-problems. By now, the input has already been divided into the smallest possible parts and we’re now going to solve them by performing basic operations. The conquer step is normally implemented with recursion by specifying the recursive base case. Once the sub-problems become small enough that it can no longer be divided, we say that the recursion “bottoms out” and that we’ve gotten down to the base case. Once the base case is arrived at, the sub-problem is solved.",,,"Ø  Combine: In this step, the solution of the sub-problems is combined to solve the whole problem. The output returned from solving the base case will be the input of larger sub-problems. So after reaching the base case we will begin to go up to solve larger sub-problems with input returned from smaller sub-problems. In this step, we merge output from the conquer step to solve bigger sub-problems. Solutions to smaller sub-problems propagate from the bottom up until they are used to solve the whole original problem.",,,129.                   ,,Dynamic Programming Approach,"Dynamic programming approach is similar to divide-and-conquer in that both solve problems by breaking it down into several sub-problems that can be solved recursively. The difference between the two is that in the dynamic programming approach, the results obtained from solving smaller sub-problems are reused in the calculation of larger sub-problems. Thus, dynamic programming is a bottom-up technique that usually begins by solving the smallest sub=problems, saving these results and then reusing them to solve larger and larger subproblems until the solution to the original problem is obtained. This is in contrast to the divideand-conquer approach, which solves problems in a top-down fashion. In this case the original problem is solved by breaking it down into increasingly smaller sub-problems, and no attempt is made to reuse previous results in the solution of any of the sub-problems.",,,"It is important to realise that a dynamic programming approach is only justified if there is some degree of overlap in the sub-problems. The underlying idea is to avoid calculating the same result twice. This is usually accomplished by constructing a table in memory, and filling it with known results as they are calculated (memoization). These results are then used to solve larger sub-problems. Note that retrieving a given result from this table takes ?(1) time. ",,,"Dynamic programming is often used to solve optimization problems. In an optimization problem, there are typically large number of possible solutions, and each has a cost associated with it. The goal is to find a solution that has the smallest cost (i.e., optimal solution)."130.                   ,,Greedy Algorithm Approach,"In a greedy algorithm, at each decision point the choice that has the smallest immediate (i.e., local) cost is selected, without attempting to look ahead to determine if this choice is part of our optimal solution to the problem as a whole (i.e., a global solution). By locally optimal, we mean a choice that is optimal with respect to some small portion of the total information available about a problem. ",,,"The most appealing aspect of greedy algorithm is that they are simple and efficient – typically very little effort is required to compute each local decision. However, for general optimization problems, it is obvious that this strategy will not always produce globally optimal solutions. Nevertheless, there are certain optimization problems for which a greedy strategy is, in fact, guaranteed to yield a globally optimal solution."131.                   ,,Randomized Approach,"This approach is dependent not only on the input data, but also on the values provided by a random number generator. If some portion of an algorithm involves choosing between a number of alternatives, and it is difficult to determine the optimal choice, then it is often more effective to choose the course of action at random rather than taking the time to determine the vest alternative. This is particularly true in cases where there are a large number of choices, most of which are “good.” ",,,"Although randomizing an algorithm will typically not improve its worst-case running time, it can be used to ensure that no particular input always produces the worst-case behavior. Specifically, because the behavior of a randomized algorithm is determined by a sequence of random numbers, it would be unusual for the algorithm to behave the same way on successive runs even when it is supplied with the same input data. ",,,Randomized approaches are best suited in game-theoretic situations where we want to ensure fairness in the face of mutual suspicion. This approach is widely used in computer and information security as well as in various computer-based games.132.                   ,,Steps Involved in Algorithm Development,"An algorithm can be defined as “a complete, unambiguous, finite number of logical steps for solving a specific problem “ ",,,"Step1. Identification of input: For an algorithm, there are quantities to be supplied called input and these are fed externally. The input is to be identified first for any specified problem. ",,,"Step2: Identification of output: From an algorithm, at least one quantity is produced, called for any specified problem. ",,,Step3: Identify the processing operations: All the calculations to be performed in order to lead to output from the input are to be identified in an orderly manner.,,,Step4: Processing Definiteness: The instructions composing the algorithm must be clear and there should not be any ambiguity in them. ,,,"Step5: Processing Finiteness: If we go through the algorithm, then for all cases, the algorithm should terminate after a finite number of steps. ",,,Step6: Possessing Effectiveness: The instructions in the algorithm must be sufficiently basic and in practice they can be carries out easily.133.                   ,,Concept of Flowcharts,"A flowchart is a visual representation of an algorithm. A flowchart is a diagram made up of boxes, diamonds and other shapes, connected by arrows. Each shape represents a step of the solution process and the arrow represents the order or link among the steps. It is a diagram that shows each step or progression through a process. A well-made flowchart can be used to break big ideas into small, bite-sized pieces that are expressed visually, so knowing how to make one is sort of like having a universal language. Being able to flowchart makes it possible to communicate with any stakeholder or audience, because visuals are typically easier to understand than words. For this reason, flowcharts are a valuable type of business diagram but can also be used for more technical fields like manufacturing or software engineering."134.                   ,,Memory Allocation,"Memory allocation is the process of assigning blocks of memory on request. Typically, the allocator receives memory from the operating system in a small number of large blocks that it must divide up to satisfy the requests for smaller blocks. It must also make any returned blocks available for reuse. There are many common ways to perform this, with different strengths and weaknesses. A few are described briefly here:",,,"Ø  First Fit: In the first fit algorithm, the allocator keeps a list of free blocks (known as the freelist) and, on receiving a request for memory, scans along the list for the first block that is large enough to satisfy the request. If the chosen block is significantly larger than that requested, then it is usually split, and the remainder added to the list as another free block. The first fit algorithm performs reasonably well, as it ensures that allocations are quick. When recycling free blocks, there is a choice as to where to add the blocks to the list effectively in order the free list is kept:",,,"Ø  Best Fit The best fit is the allocation policy that always allocates from the smallest suitable free block. Suitable allocation mechanisms include sequential fit searching for a perfect fit, first fit on a size-ordered free block chain, segregated fits, and indexed fits. Many good fit allocators are also described as best fit. In theory, best fit may exhibit bad fragmentation, but in practice, this is not commonly observed.",,,"Ø  Buddy System: In a buddy system, the allocator will only allocate blocks of certain sizes, and has many free lists, one for each permitted size. The permitted sizes are usually either powers of two, or form a Fibonacci sequence (see below for example), such that any block except the smallest, can be divided into two smaller blocks of permitted sizes.",,,Ø  Sub-allocators: There are many examples of application programmes that include additional memory management code called a sub-allocator. A sub-allocator obtains large blocks of memory from the system memory manager and allocates the memory to the application in smaller pieces. Sub-allocators are usually written for one of the following reasons: To avoid general inefficiency in the system memory manager; To take advantage of special knowledge of the application's memory requirements that cannot be expressed to the system memory manager; To provide memory management services that the system memory manager does not supply.135.                   ,,What is a Package?,"A package is a namespace for organizing classes and interfaces in a logical manner. Placing your code into packages makes large software projects easier to manage. This section explains why this is useful, and introduces you to the Application Programming Interface (API) provided by the Java platform. ",,,"Conceptually, you can think of packages as being similar to different folders on your computer. You might keep HTML pages in one folder, images in another, and scripts or applications in yet another. Because software written in the Java programming language can be composed of hundreds or thousands of individual classes, it makes sense to keep things organized by placing related classes and interfaces into packages. The Java platform provides an enormous class library (a set of packages) suitable for use in your own applications. This library is known as the ""Application Programming Interface” or “API for short. Its packages represent the tasks most commonly associated with general-purpose programming. For example, a String object contains state and behaviour for character strings; a File object allows a programmer to easily create, delete, inspect, compare, or modify a file on the file system; a Socket object allows for the creation and use of network sockets; various GUI objects control buttons and checkboxes and anything else related to graphical user interfaces. There are literally thousands of classes to choose from. This allows you, the programmer, to focus on the design of your particular application, rather than the infrastructure required to make it work."136.                   ,,Object-Oriented Programming,"Object-oriented programming (OOP) is a programming language model organised around ""objects"" rather than ""actions"" and data rather than logic. ",,,"Historically, a programme has been viewed as a logical procedure that takes input data, processes it, and produces output data. The programming challenge was seen as how to write the logic, not how to define the data. Object-oriented programming takes the view that what we really care about are the objects we want to manipulate rather than the logic required to manipulate them. Examples of objects range from human beings (described by name, address, and so forth) to buildings and floors (whose properties can be described and managed) down to the little widgets on your computer desktop (such as buttons and scroll bars).",,,"The first step in OOP is to identify all the objects you want to manipulate and how they relate to each other, an exercise often known as data modeling. Once you've identified an object, you generalise it as a class of objects (think of Plato's concept of the ""ideal"" chair that stands for all chairs) and define the kind of data it contains and any logic sequences that can manipulate it. Each distinct logic sequence is known as a method. A real instance of a class is called (no surprise here) an ""object"" or, in some environments, an ""instance of a class."" The object or class instance is what you run in the computer. Its methods provide computer instructions and the class object characteristics provide relevant data. You communicate with objects - and they communicate with each other - with well-defined interfaces called messages."137.                   ,,Java Programming Variables,"In the Java programming language, the terms ""field"" and ""variable"" are both used; this is a common source of confusion among new developers, since both often seem to refer to the same thing. ",,,The Java programming language defines the following kinds of variables: ,,,"Ø  Instance Variables (Non-Static Fields): Technically speaking, objects store their individual states in ""non-static fields"", that is, fields declared without the static keyword. Non-static fields are also known as instance variables because their values are unique to each instance of a class (to each object, in other words); the currentSpeed of one bicycle is independent of the currentSpeed of another.",,,"Ø  Class Variables (Static Fields): A class variable is any field declared with the static modifier; this tells the compiler that there is exactly one copy of this variable in existence, regardless of how many times the class has been instantiated. A field defining the number of gears for a particular kind of bicycle could be marked as static since conceptually, the same number of gears will apply to all instances. The code, static int numGears = 6; would create such a static field. Additionally, the keyword final could be added to indicate that the number of gears will never change.",,,"Ø  Local Variables: Similar to how an object stores its state in fields, a method will often store its temporary state in local variables. The syntax for declaring a local variable is similar to declaring a field (for example, int count = 0;). There is no special keyword designating a variable as local; that determination comes entirely from the location in which the variable is declared — which is between the opening and closing braces of a method. As such, local variables are only visible to the methods in which they are declared; they are not accessible from the rest of the class. ",,,"Ø  Parameters: You've already seen examples of parameters, both in the Bicycle class and in the main method of the ""Hello World!"" application. Recall that the signature for the main method is public static void main (String [] args). Here, the args variable is the parameter to this method. The important thing to remember is that parameters are always classified as ""variables"" not ""fields""."138.                   ,,Naming Conventions,"Every programming language has its own set of rules and conventions for the kinds of names that you're allowed to use, and the Java programming language is no different. The rules and conventions for naming your variables can be summarised as follows: ",,,"Variable names are case-sensitive. A variable's name can be any legal identifier — an unlimited-length sequence of Unicode letters and digits, beginning with a letter, the dollar sign ""$"", or the underscore character ""_"". The convention, however, is to always begin your variable names with a letter, not ""$"" or ""_"". Additionally, the dollar sign character, by convention, is never used at all. You may find some situations where auto-generated names will contain the dollar sign, but your variable names should always avoid using it. A similar convention exists for the underscore character; while it's technically legal to begin your variable's name with ""_"", this practice is discouraged. White space is not permitted.",,,"Subsequent characters may be letters, digits, dollar signs, or underscore characters. Conventions (and common sense) apply to this rule as well. When choosing a name for your variables, use full words instead of cryptic abbreviations. Doing so will make your code easier to read and understand. In many cases, it will also make your code selfdocumenting; fields named cadence, speed, and gear, for example, are much more intuitive than abbreviated versions, such as s, c, and g. ",,,Also keep in mind that the name you choose must not be a keyword or reserved word.139.                   ,,Characteristics of Algorithm,An algorithm must possess following characteristics: ,,,1.     Precision — the steps are precisely stated or defined. ,,,2.     Uniqueness — results of each step are uniquely defined and only depend on the input and the result of the preceding steps. ,,,3.     Finiteness — the algorithm always stops after a finite number of steps. ,,,4.     Input — the algorithm receives some input. ,,,5.     Output — the algorithm produces some output.140.                   ,,Concept of Flowcharts,"A flowchart is a visual representation of an algorithm. A flowchart is a diagram made up of boxes, diamonds and other shapes, connected by arrows. Each shape represents a step of the solution process and the arrow represents the order or link among the steps. It is a diagram that shows each step or progression through a process. ",,,"A well-made flowchart can be used to break big ideas into small, bite-sized pieces that are expressed visually, so knowing how to make one is sort of like having a universal language. Being able to flowchart makes it possible to communicate with any stakeholder or audience, because visuals are typically easier to understand than words. For this reason, flowcharts are a valuable type of business diagram but can also be used for more technical fields like manufacturing or software engineering."141.                   ,Data Base Management System,Advantages of a DBMS,"A DBMS can provide: a. Data Consistency and Integrity - by controlling access and minimizing data duplication b. Application program independence - by storing data in a uniform fashion c. Data Sharing - by controlling access to data items, many users can access data concurrently d. Backup and Recovery e. Security and Privacy f. Multiple views of data"142.                   ,,Categories of Database Management Systems (DBMS),"Database management systems are categorised according to their data structures and types. Well known types are relational, hierarchical, and object-oriented.",,,"Ø  Relational Database Management System (RDBMS): The Relational database management system organises data in tabular files. Most modern Database Management Systems (Oracle, Sybase, and Microsoft SQL Server) are relational databases. These databases support a standard language - SQL (Structured Query Language).",,,Ø  Hierarchical Database Management System (RDBMS): This category of database management system stores data in a tree-like structure.,,,Ø  Object-Oriented Database Management System (RDBMS): The Object-Oriented database management system stores objects as opposed to tuples or records in a RDBMS. DBMSs are categorized according to their data structures or types.143.                   ,,A file,A File is a collection of or log of records. Having stored the records in a file it is necessary to access these records using either a primary or secondary key. The type and frequency of access required determines the type of file organization to be used for a given set of records.144.                   ,,,"A sequential (or sorted on primary keys) file that is indexed is called an index sequential file. The index provides for random access to records, while the sequential nature of the file provides easy access to the subsequent records as well as sequential processing. An additional feature of this file system is the overflow area. This feature provides additional space for record addition without necessitating the creation of a new file."145.                  8,,,"In a sequential file, records are maintained in the logical sequence of their primary key value. The search for a given record requires, on average, access to half the records in the file. Update operations, including the appending of a new record, require creation of a new file. Updates could be batched and a transaction file of updates used to create a new master file from the existing one .This scheme automatically creates a backup copy of the file."146.                  9,,Sequential file,"Access to a sequential file can be enhance by creating an index. The index provides random access to records and the sequential nature of the file provides easy access to the next record. To avoid frequent reorganization, an index sequential file uses overflow areas. This scheme provides space for the addition of records without the need for the creation of a new file. In index sequential organization, it is the usual practice to have a hierarchy of indexes with the lowest level index pointing to the records while the higher level ones point to the index below them."147.                  9,,Properties of database,A Database has the following implicit properties: ,,,"1) A Database represents some aspect of the real world, sometimes called the mini world or the Universe of Discourse (UOD). Changes to the mini world are reflected in the database. ",,,2) A Database is a logically coherent collection of data with some inherent meaning. A random assortment of data cannot correctly be referred to as a database. ,,,"3) A Database is designed, built and populated with data for a specific purpose. It ",,,has an intended group of users and some pre-convinced applications in which ,,,these users are interested,,,,,,148.                  9,,Database,"A Database may be generated and maintained manually, or by machine. The Library card catalog is an example of database that may be manually created and maintained. A Computerized Database may be created and maintained either by a group of application programs written specifically for that task or by a database management system"149.                  9,,DBMS,"A Database Management System (DBMS) is a set of software programs that controls the organization, storage, management, and retrieval of data in a database. The DBMS accepts requests for data from an application program and instructs the operating system to transfer the appropriate data. The queries and responses must be submitted and received according to a format that conforms to one or more applicable protocols. When a DBMS is used, information systems can be changed much more easily as the organization’s information requirements change. New categories of data can be added to the database without disruption to the existing system.",,,"A Database Management System can simply be defined as a set of software programs that controls the organization, storage, management, and retrieval of data in a database. Typical examples of Database Management Systems include Oracle Database, Microsoft SQL Server, and PostgreSQL. Nowadays, a small number of DBMSs are used by the great majority of database applications to manage practically all the world‘s databases",,,150.                  9,,A Storage manager,"A Storage Manager is a Program module that provides the interface between the low level data stored in the database and the application programs and queries submitted to the system. It is also responsible for interaction with the File Manager. The Raw data are stored on the disk using the file system, which is usually provided by a conventional Operating System. The Storage Manager translates the various DML statements into low-level file-system commands. Thus the Storage Manager is responsible for storing, retrieving and updating data in the database. "151.                  9,,Relation,The Relation is the only Data Structure used in the relational data model to represent both Entities and Relationships between them. Rows of the relation are referred to as Tuples of the relation and columns are its Attributes. Each Attribute of the column is drawn from the set of values known as Domain. The Domain of an attribute contains the set of values that the attribute may assume.152.                  9,,An Entity,An Entity Set is a set of entities of the same type that share the same properties or attributes. The set of all persons who are students at a given institute can be defined as an entity set student. Similarly entity set loan might represent set of all loans awarded by a particular bank. The individual entities that constitute a set are said to be the extension of the entity set. E153.                   ,,Components of Database Management System (DBMS),"A Database Management System (DBMS) includes four main parts: modeling language, data structure, database query language, and transaction mechanisms. We will look at these components in the subsequent units.",,,"Ø  Modeling Language The first component of a database management system is the implementation of a modeling language that serves to define the language of each database hosted via the DBMS. There are several approaches currently in use, with hierarchical, network, relational, and object examples. Essentially, the modeling language ensures the ability of the databases to communicate with the DBMS and thus operate on the system.",,,"Ø  Data Query Language A third component of DBMS software is the data query language. This element is involved in maintaining the security of the database, by monitoring the use of login data, the assignment of access rights and privileges, and the definition of the criteria that must be employed to add data to the system. The data query language works with the data structures to make sure it is harder to input irrelevant data into any of the databases in use on the system.",,,"Ø  Transaction Mechanism A database transaction mechanism ideally guarantees ACID properties in order to ensure data integrity despite concurrent user accesses (concurrency control), and faults (fault tolerance). It also maintains the integrity of the data in the database. The DBMS can maintain the integrity of the database by not allowing more than one user to update the same record at the same time. The DBMS can help prevent duplicate records via unique index constraints; for example, no two customers with the same customer numbers (key fields) can be entered into the database.",,,154.                   ,,The E-R Model,"The entity-relationship model is based on a perception of the world as consisting of a collection of basic objects (entities) and relationships among these objects. In order to grasp the full notion of this model, we would describe some of the key terms highlighted above. An entity is a distinguishable object that exists. Each entity has associated with it a set of attributes describing it. E.g. number and balance for an account entity. On the other hand a relationship is an association among several entities. For example, a cust_acct relationship associates a customer with each account he or she has. Thus, the set of all entities or relationships of the same type is called the entity set or relationship set. Another essential element of the E-R diagram is the mapping cardinalities, which express the number of entities to which another entity can be associated with via a relationship set. We will see later how well this model works to describe real world situations. The overall logical structure of a database can be expressed graphically by an E-R diagram"155.                   ,,Modes of Information Integration,There are several ways that databases or other distributed information sources can be made to work together. In this section. We consider the three most common approaches:,,,"1.       Federated databases. The sources are independent, but one source can call on others to supply information.",,,"2.       Warehousing. Copies of data from several sources are stored in a single database, called a (data) warehouse. Possibly, the data stored at the warehouse is first processed in some way before storage; e.g., data may be filtered, and relations may be joined or aggregated. The warehouse is updated periodically, perhaps overnight. As the data is copied from the sources, it may need to be transformed in certain ways to make all data conform to the schema at the warehouse. ",,,"3.       Mediation. A mediator is a software component that supports a virtual database, which the user may query as if it were materialized (physically constructed, like a warehouse). The mediator stores no data of its own. Rather, it translates the user's query into one or more queries to its sources. The mediator then synthesizes the answer to the user's query from the responses of those sources, and returns the answer to the user."156.                  9,Computer Organization and Architecture,ENIAC,"The ENIAC (Electronic Numerical Integrator And Computer), designed and constructed at the University of Pennsylvania, was the world’s first general-purpose electronic digital computer. The project was a response to U.S needs during World War II. ",,,"John Mauchly, a professor of electrical engineering at the University of Pennsylvania, and John Eckert, one of his graduate students, proposed to build a general-purpose computer using vacuum tubes for the BRL’s application. In 1943, the Army accepted this proposal, and work began on the ENIAC. The resulting machine was enormous, weighing 30 tons, occupying 1500 square feet of floor space, and containing more than 18,000 vacuum tubes. When operating, it consumed 140 kilowatts of power. It was also substantially faster than any electromechanical computer, capable of 5000 additions per second. The ENIAC was completed in 1946, too late to be used in the war effort. The use of the ENIAC for a purpose other than that for which it was built demonstrated its general-purpose nature. The ENIAC continued to operate under BRL management until 1955, when it was disassembled."157.                  7,,Pipeline hazard,"A pipeline hazard occurs when the pipeline, or some portion of the pipeline, must stall because conditions do not permit continued execution. Such a pipeline stall is also referred to as a pipeline bubble. There are three types of hazards: resource, data, and control."158.                  7,,Data hazards,"A data hazard occurs when two instructions in a program are to be executed in sequence and both access a particular memory or register operand. If the two instructions are executed in strict sequence, no problem occurs but if the instructions are executed in a pipeline, then the operand value is to be updated in such a way as to produce a different result than would occur only with strict sequential execution of instructions. The program produces an incorrect result because of the use of pipelining."159.                  7,,Loop buffer,"A loop buffer is a small, very-high-speed memory maintained by the instruction fetch stage of the pipeline and containing the n most recently fetched instructions, in sequence. If a branch is to be taken, the hardware first checks whether the branch target is within the buffer. If so, the next instruction is fetched from the buffer. ",,,The loop buffer has three benefits: ,,,"1. With the use of prefetching, the loop buffer will contain some instruction sequentially ahead of the current instruction fetch address. ",,,"2. If a branch occurs to a target just a few locations ahead of the address of the branch instruction, the target will already be in the buffer. ",,,"3. This strategy is particularly well suited to dealing with loops, or iterations; hence the name loop buffer. If the loop buffer is large enough to contain all the instructions in a loop, then those instructions need to be fetched from memory only once, for the first iteration. For subsequent iterations, all the needed instructions are already in the buffer."160.                  8,,CISC,"CISC has richer instruction sets, which include a larger number of instructions and more complex instructions. Two principal reasons have motivated this trend: a desire to simplify compilers and a desire to improve performance. The first of the reasons cited, compiler simplification, seems obvious. The task of the compiler writer is to generate a sequence of machine instructions for each HLL statement. If there are machine instructions that resemble HLL statements, this task is simplified. This reasoning has been disputed by the RISC researchers. They have found that complex machine instructions are often hard to exploit because the compiler must find those cases that exactly fit the construct. The task of optimizing the generated code to minimize code size, reduce instruction execution count, and enhance pipelining is much more difficult with a complex instruction set. The other major reason cited is the expectation that a CISC will yield smaller, faster programs. Let us examine both aspects of this assertion: that program will be smaller and that they will execute faster. There are two advantages to smaller programs. First, because the program takes up less memory, there is a savings in that resource. Second, in a paging environment, smaller programs occupy fewer pages, reducing page faults. The problem with this line of reasoning is that it is far from certain that a CISC program will be smaller than a corresponding RISC program. Thus it is far from clear that a trend to increasingly complex instruction sets is appropriate. This has led a number of groups to pursue the opposite path."161.                  8,,Micro-programmed control unit,"The term micro-program was first coined by M. V. Wilkes in the early 1950s. Wilkes proposed an approach to control unit design that was organized and systematic that avoided the complexities of a hardwired implementation. An alternative for Hardwired Control Unit, which has been used in many CISC processors, is to implement a micro-programmed control unit.",,," A language is used to deign micro-programmed control unit known as a microprogramming language. Each line describes a set of micro-operations occurring at one time and is known as a microinstruction. A sequence of instructions is known as a micro-program, or firmware. ",,,"For each micro-operation, control unit has to do is generate a set of control signals. Thus, for any microoperation, control line emanating from the control unit is either on or off. This condition can, be represented by a binary digit for each control line. So we could construct a control word in which each bit represents one control line. Now add an address field to each control word, indicating the location of the next control word to be executed if a certain condition is true. ",,,"The result is known as a horizontal microinstruction. The format of the microinstruction or control word is as follows. There is one bit for each internal processor control line and one bit for each system bus control line. There is a condition field indicating the condition under which there should be a branch, and there is a field with the address of the microinstruction to be executed next when a branch is taken"162.                  8,,Key,"A key is a single attribute or combination of two or more attributes of an entity set that is used to identify one or more instances of the set. The attribute of entity set which identifies and distinguishes instances of entity set is called primary key. If we add additional attributes to a primary key, the resulting combination would still uniquely identify an instance of the entity set. Such keys are called super keys. A primary key is therefore a minimal super key.",,,163.                  8,,INSTRUCTION SET DESIGN,"One of the most interesting and most analyzed, aspect of computer design is instruction set is very complex because it affect so many aspect of the computer system. The instruction defines any of the functions performed by the processor and thus has significant effect on the implementation of the process. The instruction set is the programmer’s means of controlling the processor. Thus, programmer requirements must be considered in designing the instruction set. The most important of these fundamental design issues include the following: ",,,·       Operation repertoire: How many and which operations to provide and how complex operations should be. ,,,·       Data types: The various types of data upon which operations are perform.,,,·       Instruction format: Instruction length (in nits) number of assesses size of various fields and so on. ,,,·       Registers: Number of processor registers that can be referenced by instructions and their use. ,,,·       Addressing: The mode or modes by which the address of an operand is specified. These issues are highly interrelated and must be considered together in designing an instruction set.164.                  8,,MAIN MEMORY,"The main memory is the central storage unit in a computer system. It is a relatively large and fast memory used to store programs and data during the computer operation. The principal technology used for the main memory is based on semiconductor integrated circuits. Integrated circuit RAM chips are available in two possible operating modes, static and dynamic. The static RAM consists essentially of internal flip-flops that store the binary information. The stored information remains valid as long as power is applied to the unit. The dynamic RAM stores the binary information in the form of electric charges that are applied to capacitors. The capacitors are provided inside the chip by MOS transistors. The stored charge on the capacitors tends to discharge with time and the capacitors must be periodically recharged by refreshing the dynamic memory. Refreshing is done by cycling through the words every few milliseconds to restore the decaying charge. The dynamic RAM offers reduced power consumption and larger storage capacity in a single memory chip. The static RAM is easier to use and has shorter read and write cycles. Most of the main memory in a general-purpose computer is made up of RAM integrated circuit chips, but a portion of the memory may be constructed with ROM chips. Originally, RAM was used to refer to a random-access memory, but now it is used to designate a read/write memory to distinguish it from a read-only memory, although ROM is also random access. RAM is used for storing the bulk of the programs and data that are subject to change. ROM is used for storing programs that are permanently resident in the computer and for tables of constants that do not change in value once the production of the computer is completed. Among other things, the ROM portion of main memory is needed for storing an initial program called a bootstrap loader. The bootstrap loader is a program whose function is to start the computer software operating when power is turned on. Since RAM is volatile, its contents are destroyed when power is turned off. The contents of ROM remain unchanged after power is turned off and on again. The startup of a computer consists of turning the power on and starting the execution of an initial program. Thus when power is turned on, the hardware of the computer sets the program counter to the first address of the bootstrap loader. The bootstrap program loads a portion of the operating system from disk to main memory and control is then transferred to the operating system, which prepares the computer for general use."165.                  8,,Modes of Transfer,The binary information that is received from an external device is usually stored in the memory unit. The information that is transferred from the CPU to the external device is originated from the memory unit. CPU merely processes the information but the source and target is always the memory unit. Data transfer between CPU and the I/O devices may be done in different modes. Data transfer to and from the peripherals may be done in any of the three possible ways.,,,·       Programmed I/O. ,,,·       Interrupt- initiated I/O. ,,,·       Direct memory access (DMA).166.                  8,Human Computer Interaction,,"Heuristics evaluation is a methodical procedure to check user interface for usability problems. Once a usability problem is detected in design, they are attended as an integral part of constant design processes. Heuristic evaluation method includes some usability principles such as Nielsen’s ten Usability principles."167.                  8,,,"The objective of this chapter is to learn all the aspects of design and development of interactive systems, which are now an important part of our lives. The design and usability of these systems leaves an effect on the quality of people’s relationship to technology. Web applications, games, embedded devices, etc., are all a part of this system, which has become an integral part of our lives. Let us now discuss on some major components of this system."168.                  8,,,"Usability Engineering is a method in the progress of software and systems, which includes user contribution from the inception of the process and assures the effectiveness of the product through the use of a usability requirement and metrics. It thus refers to the Usability Function features of the entire process of abstracting, implementing & testing hardware and software products. Requirements gathering stage to installation, marketing and testing of products, all fall in this process."169.                  8,,,"Software Engineering is the study of designing, development and preservation of software. It comes in contact with HCI to make the man and machine interaction more vibrant and interactive."170.                  9,,,"Graphic User Interface (GUI) is the interface from where a user can operate programs, applications or devices in a computer system. This is where the icons, menus, widgets, labels exist for the users to access. It is significant that everything in the GUI is arranged in a way that is recognizable and pleasing to the eye, which shows the aesthetic sense of the GUI designer. GUI aesthetics provides a character and identity to any product."171.                  9,,,Gesture Recognition is a subject in language technology that has the objective of understanding human movement via mathematical procedures. Hand gesture recognition is currently the field of focus. This technology is future based.172.                  9,,,A Keyboard can be considered as a primitive device known to all of us today. Keyboard uses an organization of keys/buttons that serves as a mechanical device for a computer. Each key in a keyboard corresponds to a single written symbol or character. This is the most effective and ancient interactive device between man and machine that has given ideas to develop many more interactive devices as well as has made advancements in itself such as soft screen keyboards for computers and mobile phones.173.                  9,,Overview of the Computer System,"The computer system is made up of various elements and each of these elements affects the interaction in the following manner: Input devices are used for text entry and pointing. Output devices are used for display and print of processed data on Visual Display Unit(screen) and printer on digital paper Virtual reality affected using special interaction and dis Physical interaction carried out through sound, haptic, and bio Paper is used for printing output and for scanning inputs. Storage and memory utilized through accessing large capacity Random Access Memory ( RAM) and permanent storage media Processing carried out using high speed processing units and networks"174.                  9,,What is Human-Computer Interaction (HCI)?,"Human-computer interaction (HCI) is a multidisciplinary field of study focusing on the design of computer technology and, in particular, the interaction between humans (the users) and computers. While initially concerned with computers, HCI has since expanded to cover almost all forms of information technology design.",,,"HCI surfaced in the 1980s with the advent of personal computing, just as machines such as the Apple Macintosh, IBM PC 5150 and Commodore 64 started turning up in homes and offices in society changing numbers. For the first time, sophisticated electronic systems were available to general consumers for uses such as word processors, games units and accounting aids. Consequently, as computers were no longer room-sized, expensive tools exclusively built for experts in specialized environments, the need to create human-computer interaction that was also easy and efficient for less experienced users became increasingly vital. From its origins, HCI would expand to incorporate multiple disciplines, such as computer science, cognitive science and human-factors engineering."175.                  9,File Organization,File organization,A file is a collection of or log of records. Having stored the records in a file it is necessary to access these records using either a primary or secondary key. The type and frequency of access required determines the type of file organization to be used for a given set of records. ,,,"A File is organized logically as a sequence of records. These records are mapped onto disk blocks .Files are provided as a basic construct in operating systems, so we shall assume the existence of an underlying file system. We need to consider ways of representing logical data models in terms of files.",,," Although blocks are of a fixed size determined by the physical properties of the disk and by the operating system, record sizes vary. In a relational database, tuples of distinct relations are generally of different sizes."176.                  9,,Organization of Records in a File,"So far, we have studied how records are represented in a file structure. A relation is a set of records. Given a set of records; the next question is how to organize them in a file. Several of the possible ways of organizing records in files are: ",,,"·       Heap File Organization Any record can be placed anywhere in the file where there is space for a record. There is no ordering of records. Typically, there is a single file for each relation. ",,,"·       Sequential File Organization Records are stored in sequential order, according to the value of a “search key” of each record. ",,,·       Hashing File Organization A hash function is computed on some other attribute of each record. The result of the hash function specifies in which block of the file the record should be placed.177.                  9,,Sequential File Organization,"In a sequential file, records are maintained in the logical sequence of their primary key values. The processing of a sequential file is conceptually simple but inefficient for random access. A sequential file could be stored on a sequential storage device such as a magnetic tape.",,,"Search for a given record in a sequential file requires, an average access to half the records in the file. A binary2 or logarithmic search technique may also be used to search for a record.",,,"Updating usually requires the creation of a new file. To maintain file sequence records are copied to the point where amendment is required. The changes are then made and copied to the new file. Following this, the remaining records in the original file are copied to the new file, thus creating an automatic back-up copy."178.                  9,,Hash Files,"In the index sequential file organization considered, the mapping from the search key value to the storage location is via index entries. In direct file organizations, the key value is mapped directly to the storage location, avoiding the use of indices. The usual method of direct mapping is by performing some arithmetic manipulation of the key value. This process is called hashing. ",,,However hashing schemes usually give rise to collisions when two or more distinct key values are mapped to the same value. Collisions are handled in a number of ways .The colliding records may be assigned to the next available free space or they may be assigned to overflow area. ,,,"In using the hash function to generate a value, which is the address of a bucket where the pair values of records are stored, we can handle limited collisions as well as re-organizations of the file without affecting the hash function. In extendable hashing; the database size changes are handled by splitting or coalescing buckets."179.                  9,,Database,"It is fair to say that databases will play a critical role in almost all areas where computers are used including business, engineering, medicine, law, education and library science etc. The term Database is a collection of related data with an implicit meaning. ",,,"By Data, we mean known facts that can be recorded and that have implicit meaning. Consider the names, telephone numbers, and addresses of the people you know. We may record this data in an indexed address book, or diskette, using a personal computer and software such as FoxPro, Excel, and Access etc."180.                  1,,DBMS (Database Management System),"A DBMS (Database Management System) is a collection of programs that enables users to create and maintain a database. A DBMS is hence a general purpose s/w system that facilitates the process of Defining, Constructing and Manipulating databases for various applications.",,,"·       Defining a database involves specifying the data types, structures and constraints for the data to be stored in the database (I. specifying different types of data elements to be stored in each record). ",,,·       Constructing the database is the process of storing the data itself on some storage medium that is controlled by the DBMS. ,,,"·       Manipulating a database includes such functions as querying the database to retrieve the specific data, updating the database to reflect changes in the mini world and generating reports from the data .Data manipulation involves querying and updating. These informal queries and updates must be specified precisely in the database system language before they can be processed. Most medium and large size databases include many types of records and have many relationships among records."181.                  1,,Users of DBMS,The users of a database system can be classified according to the degree of expertise or the mode of their interactions with the DBMS.,,,1.       Naive Users:  Users who need not be aware of the presence of the database system or any other system supporting their usage are considered naïve users. A user of an automatic teller machine falls in this category. The operations that can be performed by these types of users are very limited and affect a precise portion of the database. Other such users are end users of the database who work through menu oriented application program where the type and range of response is always indicated to the user. ,,,2.       Online Users: These are the users who may communicate with the database directly via an online terminal or indirectly via a user interface and application program. These users are aware of the presence of database system and may have acquired a certain amount of expertise in the limited interaction with the database through the application program. The more sophisticated of these users may also use a data manipulation language to manipulate the database directly. Online users can also be naïve users requiring additional help such as menus. ,,,"3.       Application Programmers: Professional programmers who are responsible for developing application programs or user interfaces utilized by the naïve and online users fall into this category. The application program could be written in a general purpose programming language such as C, Assembler, FORTRAN, Pascal etc. and can include commands required to manipulate the database. ",,,"4.       Database Administrator: Centralized control of the database is exerted by a person or group of persons under the supervision of high level administrator. This person or group is referred to as the Database Administrator (DBA). They are the users who are most familiar with the database and are responsible for creating, modifying and maintaining its 3 levels."182.                  1,,Storage Manager,"The storage manager is important because databases typically require a large amount of storage space. Corporate databases range in size from hundreds of gigabytes to, for the largest databases, terabytes of data. A gigabyte is (1 billion bytes) and terabyte is 1 million megabytes (1 trillion bytes). Since the main memory of computers cannot store this much information, the information is stored on disks. Data are moved between disk storage and main memory as needed. Since the movement of data to and from disk is slow relative to the speed of the CPU. (Which minimizes need to move data from disk and main memory). ",,,"A storage manager is a program module that provides the interface between the low level data stored in the database and the application programs and queries submitted to the system. It is also responsible for interaction with the file manager. The raw data are stored on the disk using the file system, which is usually provided by a conventional operating system. The storage manager translates the various DML statements into low-level file-system commands. Thus the storage manager is responsible for storing, retrieving and updating data in the database"183.                  1,,Query Processor,The database user retrieves data by formulating a query in the data manipulation language provided with the database. The query processor is used to interpret the online user’s query and convert it into an efficient series of operations in a form capable of being sent to the data manager for execution. The query processor uses the data dictionary to find the structure of the relevant portion of the database and uses this information in modifying the query and preparing an optimal plan to access the database.184.                  1,,Types of  Query Processor,1.       DDL Interpreter - This interprets DDL statements and records the definitions in the data dictionary. ,,,"2.       DML Pre-Compiler - This translates DML statements in a query language into an evaluation plan consisting of low – level instructions that the query evaluation engine understands. A query can usually be translated into any number of alternative evaluation plans that all give the same result. The DML compiler also performs query optimization, that is, it picks the lowest cost evaluation plan from among the alternatives. ",,,3.       Embedded DML Pre-compiler: It converts DML statements embedded in an application program to normal procedure calls in the host language. The pre compiler must interact with the DML compiler to generate the appropriate code.,,,4.       Query Evaluation Engine - Which executes low-level instructions generated by the DML compiler.185.                  1,,TYPES OF DBMS,A model is an abstraction process that hides superfluous details while highlighting details important to the application in hand. A data model is a mechanism that provides this abstraction for database applications. ,,,Data modeling is used for representing entities of interest and their relationships in the database. It allows the conceptualization of the association between various entities and their attributes. A number of models for data representation have been developed. Most data representation models provide mechanisms to structure data for the entities being modeled and allow a set of operations to be defined on them. ,,,The models can also enforce a set of constraints to maintain the integrity of the data. These models differ in their method of representing the association among entities and attributes.,,,"The main models that we will study are the hierarchical, network and relational models."186.                   ,,Domain,"We define domain Di as a set of values of the same data type. The domain Di, a set having “homogeneous” members, is conceptually similar to the data type concept in programming languages. A domain like a data type may be unstructured (atomic) or structured. Domain.",,,"Di is said to be simple if all its elements are non-decomposable (i.e. atomic).In typical DBMS systems atomic domains are general sets, such as the set of integers, real numbers, character strings and so on.",,,"Atomic domains are sometimes referred to as application –Independent domains because these general sets are not dependent on a particular application. We can also define application-dependent domains by specifying the values permitted in the particular database. Structured or composite domains can be specified as consisting of non-atomic values. For instance, the domain for the attribute address which specifies street number, street name, city, state, zip or postal code is considered as composite domain. ",,,"Attributes are defined on some underlying domain. That is they can assume values from the set of values in the domain. Attributes defined on the same domain are comparable as these attributes draw their values from the same set .It is meaningless to compare attributes defined on different domains. It has become traditional to denote attributes by uppercase letters from the beginning of the alphabet. Thus A, B, C with or without subscripts denote attributes."187.                   ,,Relational Database Objects,Various types of objects can be found in a relational database. Some of the most common objects found in a relational database include: ,,,"·       Table – A table is the primary object used to store data in a relational database. When data is queried and accessed for modification, it is usually found in a table. A table is defined by columns. One occurrence of all columns in a table is called a row of data. ",,,"·       View - A view is a virtual table, in that it looks like and acts like a table. A view is defined based on the structure and data of a table. A view can be queried and sometimes updated. ",,,·       Constraint - A constraint is an object used to place rules on data. Constraints are used to control the allowed data in a column. Constraints are created at the column level and also used to enforce referential integrity (parent and child table relationships). ,,,"·       Index - An index is an object that is used to speed the process of data retrieval on a table. For example, an index might be created on a customer’s name if users tend to search for customers by name. The customer names would be stored alphabetically in the index. The rows in the index would point to the corresponding rows in the table, much like an index in a book points to a particular page. ",,,"·       Trigger - A trigger is a stored unit of programming code in the database that is fired based on an event that occurs in the database. When a trigger is fired, data might be modified based on other data that is accessed or modified. Triggers are useful for maintaining redundant data. Procedure - A procedure is a program that is stored in the database. A procedure is executed at the database level. Procedures are typically used to manage data and for batch processing."188.                   ,,DBMS Components,A database system has several subsystems.,,,·       The storage manager subsystem provides the interface between the low level data stored in the database and the application programs and queries submitted to the system.,,,·       The query processor subsystem compiles and executes DDL and DML statements.,,,·       Transaction management ensures that the database remains in a consistent (correct ) state despite system failures .The transaction manager ensures that concurrent transaction executions proceeds without conflicting.,,,"·       Database applications are typically broken up into a front-end part that runs at client machines and a part that runs at the back end. In two tier architectures, the front end directly communicates with a database running at the back end. In three tier architectures, the back end part is itself broken up into an application server and a database server."189.                   ,,ENTITY-RELATIONSHIP MODEL,ER model is a popular high level conceptual data model. Earlier commercial systems were based on the hierarchical and network approach. The ER model is a generalization of these models. It allows the representation of explicit constraints as well as relationships. ,,,"Even though the ER model has some means of describing the physical database model, it is basically useful in the design and communication of the logical database model. ",,,"In this model, objects of similar structure are collected into entity set. The relationship between entity set is represented by a named ER relationship and is 1:1, 1:M or M:N., mapping from one entity set to another. The database structure, employing the ER model is usually shown pictorially using ERDs. ",,,"ER model consist of basic objects, called entities and relationship among these objects. It represents overall logical structure of a database. The database structure, employing the ER model is usually shown pictorially using ERDs. Semantic modeling is known by many names including data modeling, Entity relationship modeling, entity modeling and object modeling. ER model was introduced by Chen in 1976 and refined in various ways by Chen and numerous others since that time. It is one of the several semantic data models ER model is based on 3 basic concepts."190.                   ,,Entity set,An Entity is a thing or object in the real world that is distinguishable from all other objects. It is an object of interest to an organization. E.g. Each person in an enterprise.,,, Each student in the institute ,,,Loan in bank etc. ,,,"For instance a student has student-id which uniquely identifies one particular student in the institute. Similarly, loans can be thought of as entities and loan number at particular branch uniquely identifies a loan entity. ",,,"An entity may be concrete, such as a person or a book, or it may be abstract such as loan, holiday.",,,"Objects of similar types are characterized by the same set of attributes or properties. Such similar objects form an entity set or entity type. Two objects are mutually distinguishable and this fact is represented in the entity set by giving them unique identifiers. Objects are represented by their attributes and as objects are interdistinguishable, a subset of these attributes forms a primary key or a key for uniquely identifying an instance of an entity."191.                   ,,File Attributes,"The particular information kept for each file varies from operating system to operating system. No matter what operating system one might be using, files always have certain attributes or characteristics. Different file attributes are discussed as follow.",,,"·       File Name: The symbolic file name is the only information kept in human-read form. As it is obvious, a file name helps users to differentiate between various files.",,,"·       File Type: A file type is required for the systems that support different types of files. As discussed earlier, file type is a part of the complete file name. We might have two different files; say “cit381.doc” and “cit381.txt”. Therefore the file type is an important attribute which helps in differentiating between files based on their types. File types indicate which application should be used to open a particular file.",,,"·       Location: This is a pointer to the device and location on that device of the file. As it is clear from the attribute name, it specifies where the file is stored.",,,"·       Size: Size attribute keeps track of the current size of a file in bytes, words or blocks. The size of a file is measured in bytes. A floppy disk holds about 1.44 Mb; a Zip disk holds 100 Mb or 250 Mb; a CD holds about 800 Mb; a DVD holds about 4.7 Gb.",,,"·       Protection: Protection attribute of a file keeps track of the access-control information that controls who can do reading, writing, executing, and so on. ",,,·       Usage Count This value indicates the number of processes that are currently using (have opened) a particular file. ,,,"·       Time, Date and Process Identification: This information may be kept for creation, last modification, and last use. Data provided by this attribute is often helpful for protection and usage monitoring. Each process has its own identification number which contains information about file hierarchy."192.                   ,,File Organization and Access Methods,"In this unit, we use the term file organization to refer to the structure of a file (especially a data file) defined in terms of its components and how they are mapped onto backing store. Any given file organization supports one or more file access methods. Organization is thus closely related to but conceptually distinct from access methods. Access method is any algorithm used for the storage and retrieval of records from a data file by determining the structural characteristics of the file on which it is used.",,,"In choosing a file organization, several criteria are important: ",,,• Short access time ,,,• Ease of update ,,,• Economy of storage ,,,• Simple maintenance ,,,• Reliability. ,,,"The relative priority of these criteria will depend on the applications that will use the file. For example, if a file is only to be processed in batch mode, with all of the records accessed every time, then rapid access for retrieval of a single record is of minimal concern. A file stored on CDROM will never be updated, and so ease of update is not an issue. These criteria may conflict. For example, for economy of storage, there should be minimum redundancy in the data. On the other hand, redundancy is a primary means of increasing the speed of access to data. An example of this is the use of indexes."193.                   ,,The Pile/Serial,"The least-complicated form of file organization may be termed the pile/serial. Data are collected in the order in which they arrive. Each record consists of one burst of data. The purpose of the pile/serial is simply to accumulate the mass of data and save it. Records may have different fields, or similar fields in different orders. Thus, each field should be self-describing, including a field name as well as a value. The length of each field must be implicitly indicated by delimiters, explicitly included as a subfield, or known as default for that field type. Because there is no structure to the pile/serial file, record access is by exhaustive search. That is, if we wish to find a record that contains a particular field with a particular value, it is necessary to examine each record in the pile until the desired record is found or the entire file has been searched. If we wish to find all records that contain a particular field or contain that field with a particular value, then the entire file must be searched. ",,,"Pile/serial files are encountered when data are collected and stored prior to processing or when data are not easy to organize. This type of file uses space well when the stored data vary in size and structure; is perfectly adequate for exhaustive searches, and is easy to update. However, beyond these limited uses, this type of file is unsuitable for most applications."194.                   ,,File Management System,"The file management system, FMS is the subsystem of an operating system that manages the data storage organisation on secondary storage, and provides services to processes related to their access. In this sense, it interfaces the application programs with the low-level media-I/O (e.g. disk I/O) subsystem, freeing on the application programmers from having to deal with low-level intricacies and allowing them to implement I/O using convenient data-organisational abstractions such as files and records. On the other hand, the FMS services often are the only ways through which applications can access the data stored in the files, thus achieving an encapsulation of the data themselves which can be usefully exploited for the purposes of data protection, maintenance and control. Typically, the only way that a user or application may access files is through the file management system. This relieves the user or programmer of the necessity of developing special-purpose software for each application and provides the system with a consistent, well-defined means of controlling its most important asset."195.                   ,,Operations Supported by File Management System,Users and applications wish to make use of files. Typical operations that must be supported include the following: ,,,"Ø  Retrieve _All Retrieve all the records of a file. This will be required for an application that must process all of the information in the file at one time. For example, an application that produces a summary of the information in the file would need to retrieve all records. This operation is often equated with the term sequential processing, because all of the records are accessed in sequence. ",,,"Ø  Retrieve _One This requires the retrieval of just a single record. Interactive, transaction-oriented applications need this operation. ",,,"Ø  Retrieve _Next This requires the retrieval of the record that is “next” in some logical sequence to the most recently retrieved record. Some interactive applications, such as filling in forms, may require such an operation. A program that is performing a search may also use this operation.",,,"Ø  Retrieve _Previous Similar to Retrieve_Next, but in this case the record that is “previous” to the currently accessed record is retrieved. ",,,Ø  Insert _One Insert a new record into the file. It may be necessary that the new record fit into a particular position to preserve a sequencing of the file. ,,,Ø  Delete_One Delete an existing record. Certain linkages or other data structures may need to be updated to preserve the sequencing of the file.,,,"Ø  Update_One Retrieve a record, update one or more of its fields, and rewrite the updated record back into the file. Again, it may be necessary to preserve sequencing with this operation. If the length of the record has changed, the update operation is generally more difficult than if the length is preserved. ",,,"Ø  Retrieve_Few Retrieve a number of records. For example, an application or user may wish to retrieve all records that satisfy a certain set of criteria."196.                   ,,Path Names,"When a file system is organised as a directory tree, some way is needed for specifying the filenames. The use of a tree-structured directory minimizes the difficulty in assigning unique names. Any file in the system can be located by following a path from the root or master directory down various branches until the file is reached. The series of directory names, culminating in the file name itself, constitutes a pathname for the file. Two different methods commonly used are: ",,,• Absolute Path name ,,,• Relative Path name,,,"Ø  Absolute Path Name With this path name, each file is given a path consist of the path from the root directory to the file. As an example, the file in the lower lefthand corner of Figure 09 has the pathname User_B/Word/Unit_A/ABC. The slash is used to delimit names in the sequence. The name of the master directory is implicit, because all paths start at that directory. Note that it is perfectly acceptable to have several files with the same file name, as long as they have unique pathnames, which is equivalent to saying that the same file name may be used in different directories. In this example, there is another file in the system with the file name ABC, but that has the pathname /User_B/Draw/ABC.",,,"Ø  Relative Path Name Although the pathname facilitates the selection of file names, it would be awkward for a user to have to spell out the entire pathname every time a reference is made to a file. Typically, an interactive user or a process has associated with it a current directory, often referred to as the working directory or current directory. Files are then referenced relative to the working directory. For example, if the working directory for user B is “Word,” then the pathname Unit_A/ABC is sufficient to identify the file in the lower left-hand corner of Figure 09. When an interactive user logs on, or when a process is created, the default for the working directory is the user home directory. During execution, the user can navigate up or down in the tree to change to a different working directory."197.                   ,,Repositioning a File,"When repositioning a file, the directory is searched for the appropriate entry, and the current file position is set to a given value. This file operation is also called file seek. ",,,"a.     Truncating a File The user may erase some contents of a file but keep its attributes. Rather than forcing the user to delete the file and then recreate it, this operation allows all the attributes to remain unchanged, except the file size. ",,,"b.     Deleting a File To delete a file, the directory is searched for the named file. Having found the associated directory entry, the space allocated to the file is released (so it can be reused by other files) and invalidates the directory entry. ",,,"c.     Renaming a File It frequently happens that user needs to change the name of an existing file. This system call makes that possible. It is not always strictly necessary, because the file can always be copied to a new file with the new name, and the old file then deleted. ",,,"d.     Appending a File This call is a restricted form of WRITE call. It can only add data to the end of the file. System that provide a minima set of system calls do not generally have APPEND, but many systems provide multiple ways of doing the same thing, and these systems sometimes have APPEND."198.                   ,,Methods of Blocking,"Given the size of a block, there are three methods of blocking that can be used, namely; fixed, variable-length and variable-length unspanned spanning. ",,,"a.     Fixed Blocking Fixed-length records are used, and an integral number of records are stored in a block. There may be unused space at the end of each block. This is referred to as internal fragmentation. File fragmentation is defined as a condition in which files are broken apart on disk into small, physically separated segments. ",,,"b.     Variable-Length Spanned Blocking Variable-length records are used and are packed into blocks with no unused space. Thus, some records must span two blocks, with the continuation indicated by a pointer to the successor block. ",,,"c.     Variable-Length Unspanned Blocking Variable-length records are used, but spanning is not employed. There is wasted space in most blocks because of the inability to use the remainder of a block if the next record is larger than the remaining unused space."199.                   ,,Methods of Improving Performance,"a.     Block Caching The most common technique used to reduce disk accesses is the block cache or buffer cache. (Cache is pronounced “cash,” and is derived from the French cacher, meaning to hide.) In this context, a cache is a collection of blocks that logically belong on the disk, but are being kept in memory for performance reasons. Various algorithms can be used to manage the cache, but a common one is to check all read requests to see if the needed block is in the cache. If it is, the read request can be satisfied without a disk access. If the disk is not in the cache, it is first read into the cache, and then copied to wherever it is needed. Subsequent requests for the same block can be satisfied from the cache. ",,,"b.     Reduction in Disk Motion Caching is not the only way to increase the performance of a file system. Another important technique is to reduce the amount of disk arm motion by putting blocks that are likely to be accessed in sequence close to each other, preferably in the same cylinder. When output file is written, the file system has to allocate the blocks one at a time, as they are needed. If the free blocks are recorded in a bit map, and the whole bit map is in the main memory, it is easy enough to choose a free block as close as possible to the previous block. With a free list, part of which is on disk, it is much harder to allocate blocks close together. However, even with a free list, some block clustering can be done. The trick is to keep track of disk storage not in blocks, but in groups of consecutive blocks. If a track consists of 64 sectors of 512 bytes, the system could use 1K blocks (2 sectors), but allocate disk storage in units of 2 blocks (4 sectors). This is not the same as having a 2K disk block, since the cache would still use 1K but reading a file sequentially on an otherwise idle system would reduce the number of seeks by a factor of two, considerably improving performance. A variation on th"200.                   ,,User Authentication,"A major security problem for operating systems is authentication. The protection system depends on the ability to identify the programs and processes currently executing, which in turn depends on the ability to identify each user of the system. The process of identifying users when they log on is called user authentication. How do we determine whether a user's identity is authentic? Generally, authentication is based on one or more of three items: ",,,• User possession (a key or card) ,,,• User knowledge (a user identifier and password) ,,,"• User attributes (fingerprint, retina pattern, or signature).",,,
